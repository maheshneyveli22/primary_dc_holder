AZ1014 
Learning Content: https://learn.microsoft.com/en-us/training/paths/az-104-administrator-prerequisites/

1) Azure Administrator Role
a) Cloud Administrators manage the cloud services that span storage, networking and compute cloud capabilities, with a deep understanding of each service across the full IT life cycle 
b) They take end-user requests for new cloud applications and make recommendations on services to use for optimal performance and scale, as well as provision, capacity, monitor and adjust as appropriate. 
 -> this role requires communicating and coordinating with vendors 
c) Cloud Administrators use the Azure portal and as they become proficience, they use powershell and command line interface 

2) Study Areas:
a) Manage Azure identities and Governance 
b) Implement and Manage storage 
c) Deploy and manage Azure compute resources 
d) Configure and Manage virtual networking 
e) Monitor and backup resources 

3)  Configure Microsoft Entra ID (formerly Azure Active Directory) 
a) In this module we will be looking at administration of Identity at Azure environment. 
-> Specifically we will be looking at Entra ID 
-> Entra ID will be the main Identity platform in Azure ecosystem 

b) Objectives - Microsoft Entra ID;
i) Describe Microsoft Entra ID benefits and features 
ii) Describe Microsoft Entra ID concepts 
iii) Compare Microsoft Entra ID to Active Directory Domain Services 
iv) Select Microsoft Entra ID plans and Pricing 
v) Configure Device Identities 
vI) Implement Selef service Password Reset(SSPR) 


3.1) Microsoft Entra ID Benefits and features 
a) Entra ID is a fully managed service 
-> Entra ID is a modern authentication platform 
-> It supports Open ID and OAuth frameworks as its primary mechanisms of Authentication 
-> It still has concepts of Users and groups , 
----> still has separarate layers of Authentication and Authorization 
-> Has great capabilities in the form of hybrid Identity infrastructure 
b) Hybrid Identity Infrastructure 
-> It helps to internlink with your existing identity components in On premises , hence people will have consisten login format 


3.2) Entra Id Concepts and Terminologies:
a) Tenant/Directory 
-> It is your unique organizational representation in the Entra ID infrastructure space 
-> it is your dedicated and trusted instance, that contains all of your organizational data. 
-> Any users or groups or devices that are registered will get stored here. 

a.1) 
---> Terms Tenant and directory are used interchangeably . i.e Both Tenant and Directory refer the same thing 
---> Thus if i Say Tenant or Directory then i refer to representation of your single organization 

a.2) What gets stored in Tenant:
Object:
a) Different types of objects gets stored in the directory. But the keyword here is Object. 
-> Object is just a record somewhere in that directory 

Identity
b) An identity is any object that can be authenticated. 
eg: service principle, device , user 

Account
c) An identity that has data associated with it 
Data like emails, names that are specific to people 


Microsoft Entra ID Account: 
d) -> There are few different ways that we can Create accounts with Entra ID 
-> But there is one Specify type which is: Entra ID account 

-> Entra ID account is an ID that we create directly through Entra ID or synchronize from one of your directories 

Cloud Only Account 
e) 
-> IF we are creating our account directly through portal or one of our command line interfaces , that account is called Cloud-Only account (in colloquial manner) 

Azure Subscription 
f) Used to pay for Azure cloud services 
-> This is the  security and billing boundary where we home resources like virtual machines, storage accounts, SQL databases 
-> subscription gets home to a Tenant 
-> We know what organization they belong to 
-> But authorization layers happen separately 


3.3) Entra ID vs Active Directory Domain services 
a) Microsoft Entra ID is primarily an identity solution alone
-> No concept of GPOs(group policy objects) to be able to affect machines and affect things in different ways. 
b) Entra ID primarily Queried using Rest API over HTTP and HTTPS 
c) Uses HTTP and HTTPS protocols such as SAML, WS- federation and Open ID connect for Authentication( and OAuth for Authorization) 
d) Includes Federation services and many third party services(such as facebook)
e) Microsoft Entra ID users and groups are created in flat structure and there are no Organization Units(OUs) or Group Policy Objects(GPOs) 
-> Active domain services is structured around idea of nested forest where we have a forest and many different levels of hierarchy using which we build things like Organizational units or specific permissions for users 
-> But Entra ID is built entirely in a flat structure where Users, Groups, devices all of these exist at the same hierarchy level 
f) We use different types of metadata to decide how things are related to one another. 

g) Select Microsoft Entra Plans and Pricing 

Free:
Single sighn on(unlimited) 
Cloud and Federated Authentication 
Self service account management portal 
Multifactor Authentication 

P1:
Advanced Group management 
Conditional access 
Automated user and group provisioning to apps 

P2 
Risk based conditional access(sign-in risk, user risk) 
Privleed Identity mangement 

Governance 
Automated User and group provisioning to apps 
Privileged idenitity managment 

-> Conditional access means checking right country, right device etc 

-> Risk based conditional access: if user is individual sign in or from group. if account has been compromised broadly 

h) Governance:
Privleged identity Managment /Risk based conditional access 

3.4) Configure Device Identities;
-> So far what we have seen in based on concept of users 
-> Another type of object that we can add into our environment is : device 

-> We can interface devices directly with Entra ID either through a registering process or direct joining process 



a) Registered Devices:
-> Registered device is something that some one can bring themselves 
i.e Bringing our own device. Head to local laptop store, buy new lap top, login with work account and access work content 
-> Registered devices cover a number of different device types beyond traditional laptops 
-> OS - Windows 10+ ,IOS , Android and MacOS 


b) Joined Device:
-> It is going to be organizationally owned because we are getting more privilege for what users can access and you as an organization also get a lot more privileges about what you can do to that device. 
 

---> Registered vs Joined Device:
----> Difference between registered and joined device is all about: where the device is being sourced from. 


c) Hybrid Joined Devices:
-> Useful for organizations that already have active directory Domain services present in a robust manner with its complex group policies
-> if you are looking to use existing image solutions for creating standard operating environments and wish to continue utilizing them but also want to take advantage of many of the features of Entra ID - Then client should look to use Hybrid model. 
-> Supports wide range of Windows devices 
--> OS - Windows 7+ devices 



3.5) Implement Self-Service Password Reset :
-> There are different ways to interface with Entra ID : 
1) Using synchronization : Everyone has their own On-Prem account  and 2) you can interface natively with the cloud. 
a) No matter what method we use to interface with Entra ID, 
we can allow users to do: Self service Password Reset. 
b) People working in self service desk will be burdened with multiple requests for Password reset. 
-> this burden can be avoided on help desk, by setting up self service password reset -> which from a user's perspective: is the same process  as enrolling for MFA. 

Process for adding MFA for an administrator/self service desk involves: adding questions, 

c) Implementing Self service Password Reset:
-> Determine who can use self service password reset 
-> Choose  the number of authentication methods required and the methods available(email, phone, questions) 
-> you can require users to register for SSPR( same process as MFA) 


3.6) Recap:
a) Entra ID is the primary store for your organization's user group and device data 
b) Allows you to interface natively through modern authentication protocols directly with the cloud 
c) No matter how you choose to interace users into your environment, it provides you a great method to be able to ensure that it is going to be monitored, secured, audited and handle everything you need 
d) Ability to support hybrid entities 
e) Feature of self service password reset (SSPR) 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-3


4) Administer Identity: Configure Users and Group Accounts: 
-> In this lesson, we will be looking on administration of identity in azure environment. 
-> Specifically we are going to look at how user and group accounts work with Entra ID 


Learning Objectives:
i) Create User accounts 
ii) Manage User accounts 
iii) Create Bulk accounts 
iv) Create Group accounts 
v) Assign licenses to Users and Groups 
vi) Create Administrative Units Demonstration - Users and Groups 

vii) Create Users and groups 
viii) Manager user and group properties 
ix) Manage external users 
x) Manage licenses 
vii) Summary and Resources 

a) Create User Accounts:
-> In your environment, all users whether they do administration or access the portal , users will need and account 
-> User account can come from a number of sources and we can track account type of users by looking at two columns 
  i) User Type 
  ii) Directory Synced 
  
a.1) User type tells whether some one is external or internal user. 
-> Because we have ability to collaborate with external people who come into our organization as equals 
a.2) If some one is listed as member , we know that they are internal to our organization 
TWO TYPES OF INTERNAL USERS: 
-> There are two different types of people that are internal to our organization

eg: Mika is not directory synced 
-> it means that we have created their user account directly in the portal 
-> This account is also called cloud only account. 


eg: Another user: "Retail Crisis Notifications" is directory synced. 
-> This means that it has come from an Active directory Domain services which is on prem and we have synchronized that account to the cloud 

A.3) Guest user Type: 
-> Guests are sometimes referred to as B2B users 
-> Collaborators that we have invited to our environment and work alongside other administrators 


a.4) New Guest user button will add new guest user. 
-> No matter how we bring users to our environment, few core components remain the same. 
-> This account is used for their authentication into Entra ID and we can apply authentication to it. We can give them a role that is relevant to what they need to accomplish on day to day basis 

a.5) Each user account has many additional properties like Managers, alternative email and phone numbers 

a.6) Creating individual user accounts can be done in different ways but an individual who is going to create those accounts needs to be a high level administrator 
-> Either he must be a global administrator  which is one of the top levels in  Entra ID or User Administrator  to manage users 
-> In the process of adding user accounts, we can add those extra information 
-> For every user we do have ability to delete and undelete them 
-> Deleted users can be restored in 30 days 
-> Sign in and audit log  information is available for all users whether Cloud only or on prem users - all audit log information will be maintained 

a.7) To add large number of users  or if you want to make changes to large number of users in an environment - there are couple of ways to accomplish it

a) Use Bulk create or Bulk invite  
-> Bulk create helps to create or edit number of users at a time 

--> To do this, you should be Global administrator or User Administrator 

b) Creating Group Accounts:
-> There are two sub types of a group account 
i) Security groups 
ii) Microsoft 365 groups 

b.1)  M 365  groups is used in teams and ADo to give permissions in that space 

b.2) In Azure we use security groups 
-> These Allow us to apply roles 
-> Role based access control is extremely important when it comes to accessing azure resources and ensuring you have permissions to do what you need to do 
b.3) What we end up is - creating groups that represent different parts of our environment and different role people have. 

b.4) In our sample, We create 3 groups 
1) Managers
2) Virtual Machine administrators 
3) Virtual Network administrators

-> We can add users to groups and then assign permissions 

Assignment types 
b.5) Adding users to groups 
-> Individually assign someone to a group 

b.6) Dynamically adding users to a group
-> Via User information 

b.7) Dynamic Device (Security groups only) 
-> For security groups we can add people dynamically based on device that they make use of 

b.8) Organizations use groups TO ASSIGN LICENSES TO USERS AND GROUPS 

C) Create Administrative Units :
c.1) 
Lets have a University which has a number of different schools and each one of those schools has separate department like business, accounting, IT etc 

c.2) Administrative units allow us to have administrators with general roles that we have in azure, but only get permissions to administer the users and groups that are also in that admin unit 
-> It is away of segregating IT departments based on permissions 


5) Configure Subscriptions and Configure Azure Resource Manager(ARM) Resources: 

Objectives:
1) Identify regions 
2) Implement Azure subscriptions 
3) Identify Subscription usage 
4) Obtain a Subscription 
5) Create Resource groups 
6) Determine Service limits and quotas 
7) Create an Azure Resource Hierarchy 
8) Apply Resource Tagging 
9) Manage Costs 
10) Learning Recap 
11) Configure Resource Locks 
12) Apply and manage tags on resources 
13) Manage resource groups 
14) Manage subscriptions 
15) Manage Costs by using alerts, budgets and Azure adviser recommendations 
16) Configure Management groups 


In this lesson, we will seeing about: 
-> Subscriptions, 
-> where we store our Azure resource and also the resources themselves, 
-> what region is, 
-> how you utilize your subscriptions, 
-> Hierarchy between subscription,resource groups and resources.  
-> Protecting resources etc 

a) Identify Regions
-> Region is a collection of datacenters 
---> Region is some location in the world, where you are able to host your infrastructure
-> Worldwide there are 60+ regions representing 140 countries 


-> We can choose a region, where our customers are located 
->  Region provides flexibility and scale 
->  Preserves data residency 
-> Select regions close to your users 
-> Be aware of region deployment availability 
-> There are global services that are region independent 
-> Regions are paired for high availability 

-> If a service is globally deployed, means it will be deployed globally in all regions simultaneously 
 eg: Website Optimization , DNS , Entra ID 
 
-> Regions are not used at subscription level but at the resource level. 


b) Implement Azure subscriptions 
-> Azure subscription can be utilized in many different ways. 

b.1) Eg model for subscription   

Azure Account --------------->  Dev Subscription 
                      |
					  |
					  |
					  |
					  -------> Test Subscription 
					  |
					  |
					  |
					  |
					 --------> Production Subscription 
					 


-> There are different models for subscription 

b.2) Subscription is just a logical unit. 
-> It is something to divide your resources into different boundaries 
-> Security and billing boundary 

-> Ability to split different business units into different subscriptions to ensure that you have accountability for cost or having different susbcriptions within Dev, Test and Production Subscription to ensure that there are security boundaries. 



b.3) Identify Subscription Usage:

Free -> Includes a $200 credit for the first 30 days, free limited access for 12 months 
Pay as you go - Charges you monthly 
CSP - Agreement with possible discounts, through  Microsoft cloud solutions Provider partnet - Typically for small and medium businesses. 
Enterprise - One Agreement, with discounts for new licenses and Software Assurance - targeted at large enterprise-scale organizations 
Student - Includes $200 for 12 months - must verify student access. 

b.4) different ways of obtaining subscriptions:

Enterprise Agreement : Customers make an upfront monetary commitment and consume services throughout the year. - for enterprise-scale subscription 
Resellers - provide a simple, flexible way to purchase cloud services 
Partners - can design and implement your azure cloud solution 
Personal free account - Start right away ---> for free susbcriptions

c) Create Resource Groups 
-> Beyond subscription, there are number of different ways of dividing and categorizing resources within that subscription.

Subsciption
       |
	   |
	   |
	 Resource Group  

c.1) From hierarchy perspective, we have Subsciption at the top level and below that we have the resource group  
-> Resource group allows us to logically group resources together. 

c.2) Resource group is stored in a location : that's where we keep the metadata about what tags we need to put in  and all the bits and pieces about the resource group itself. 
-> But it can contain resource groups from multiple different locations 
---> This means that one resource group can represent a Global application or a particular line of Business or particular environment. 

c.3) Setting up resource groups is an organizational choice. 
-> you cant rename or nest resource groups, but we can move resources between groups. 

c.4) Examples of resource group :

---> Resources grouped: Web + DB+ VM+ Storage in one group 
-> Each resource in a Resource group: 
   Web and DB in resource group 
   Virtual machine in a resource group 
   Storage in resource group. 
   
   
d) Determine Service Limits and Quotas 
-> While spinning subscriptions and start building into multiple resource groups representing multiple business applications - you need to pay attention to service limits and quotas for your subscription.  

d.1) Within an environment, there is a default subscription quota, to ensure that users go into large amounts of Virtual machines or big amounts of storage accounts scale out. 
-> But we want to ensure that initial usage is kept relatively low and then request for increased resources 
--> before we deploy project, we should check limits and quotas 

d.2) We can view Usage And Quotas in any azure subscription. If subscription name is ASC Dev Demo, 

ASC Dev Demo(Subscription) |  Usage + quotas 

d.3) Thus Usage+ quotas help to track current usage and plan for future use 

d.4) We can open a free support case to increase limits to published maximums 

d.5) We can also build automated alerts if needed. 

e) Create an Azure Resource Hierarchy : 
-> Subscription will be our billing security hierarchy. We have resource groups below that and logically flowing down  


e.1) Above the subscription, we have a grouping mechanism  
-> This is for management only, hence we call it as management groups

e.2) Management groups provide a level of scope above subscriptions 
-> It is designed as a way to roll out consistent policies/consistent permissions and consistent budget across multiple subscriptions that share a common purpose.  

e.3) In the top : Root Managment Group  we put all our core policies that apply to our entire environment
-> Followed by that , we have Management groups that represent each line of business within the environment. eg: Human Resources, IT, Markettting  
        ------------> Management groups allows you to set the policies, set those permissions, set the things that need to be done for invidual parts of an organization 
		 


Root Managment Group ---------------------------------------------------------------------------------
                         |                     |         |						|                 	|
					     |                     |	     |						|                 	|
						 |                     |         |						|                 	|
				Human Resources(RMG)         IT(RMG)    Marketting(RMG)     EA Subscription       EA Subscription
				|                |             |          |
				|				 |             |          |
				|			     |        Production      -------Free Trial Subscription
		Dev/Test Subsciption   Apps(RMG)   (RMG)          |
                                             |            |
											 |		      |
											 |			  -------Free Trial Subscription 
											 |
											 |
							-------------------------------------------------------               
							|													|
							|                                           		|
					Geo Region 1----------                              Geo Region 2---------- 
					      |               |                                   |               |
						  |               |                             	  |               |
					EA Subscription     EA Subscription                 EA Subscription     EA Subscription 
			

f) Create Resource manager Locks:
------>  If you have a resource that needs to have changes prevented, we have a mechanism called resource lock . 
-> Applying resource lock at the subscription, resource group or resources level helps to prevent changes 


f.1) We can apply the Resource manager lock to Subscription, Resource group or Resource and it ends at resources 
f.2) Locks get inherited by child resources 

Readonly Locks and Delete Locks 
f.3) Read only licks prevent any changes to the resource 
f.4) Delete locks prevent deletion 

g) Resource Manager benefits 
g.1) A resource in our structure having Resources, Resource Groups , Subscritpions ---> There is Azure Resource manager which helps in having consistent permissions 
-> Azure Resource Manager(ARM) acts as translation layer for the things we need to do 
-> We can provide inputs to ARM via Portal or Powershell or Azure cli or Rest clients and manage permissions 



Azure Portal                  Azure Power Shell              Azure CLI                         Rest Clients 
    |                             |                           |                                  |
    |                             |                           |                                  |
	|                            -------------------------------                                 |
	|										|                                                    |
	|										|                                                    |
	|									   SDKs                                                  |
	|									    |                                                    |
	|										|                                                    |
---------------------------------------------------------------------------------------------------	
                                            |
											|
							Azure Resource Manager <---------------------------> Authentication
									|
									|
	---------------------------------------------------------------------------------
	|					|				|								|
	|					|				|								|
	|					|				|								|
Data store            Web App      Virtual Machine               Service Management           Other Services 


g.1) ARM enables you to work with resources in your solution as a group 
g.2) Deploy, update or delete in asingle, cooardinated operation 
g.3) Provides security , auditing and tagging features 
-> Tagging helps to add custom meta data on resources or resource groups in key pair format 
g.4) Choose the tools and APIs that work best for you 


h) Apply Resource Tagging:
-> Tagging provides metadata for your azure resources 
-> Tagging helps organize resources 
-> Tagging consists of a name-value pair 
-> Verfy useful for rolling up billing information 


i) Manage Costs:
-> Cost Management portal in azure helps to manage costs 
i.1) Costs are resource specific 
i.2) Usage costs may vary between locations 
i.3) Costs for inbound and outbound data transfers differ 
i.4) Prepay with azure reserved instances 
i.5) use your on premises licenses with Azure hybrid benefit 
i.6) Optimize with alerts, budgets and azure advisor recommendations 

-> Make sure you look at network traffic, understand inbound/outbound traffic , since it has different cost associated with it 
--> A lot of time, in bound network traffic does not have a cost associated with it 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-4  ends here 



6) AZ-104 Configure Azure Policy (5 of 31) 
-> comes under Manage Azure Identities and Governance(20-25%): Manage Subscriptions and Governance - Configure and Manage azure policy 
https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-5

Learning Objectives - Azure policy 
-> Implement Azure Policy
-> Create Azure Policies 
-> Demonstration - Azure Policies 
	-> Create Policy Definitions 
	-> Create and scope the initiative definition 
	-> Determine Compliance 

a) Azure policies is a simple mechanism to find compliance in your environment 
 -> Compliance is for a range of different things 
 -> It has technical controls to assess whether someone has done something correctly 
 -> Evaluation that runs within Azure policy is constant 
 -> So we will get an update to know where are we in terms of compliance and what you need to do remedieate your environment to bring yourself to a compliant state. 
 
 
a.1) Azure policies is a service to create, assign and manage policies 
-> Runs evaluations and scans for non compliant resources 

Advantages:
-> enforcement and compliance 
-> Apply policies at scale 
-> remediation 

a.2) Azure policy use cases 
-> Allowed resource types - Specify the resource types that your organization can deploy 

Allowed virtual machine SKUs - Specify a set of virtual machine SKUs that your organization can deploy 

Allowed Locations : Restrict locations your organization can specify while deploying resources 

Require Tag and its value: enforces a required tag and its value 

Azure backup should be enabled for virtual machines - Audit if azure backup service is enabled for all virtual machines 

a.3) Create Azure Policies 

a.3.1) Define and Create 

Policy Initiative: 
Policy Definition(s): 
-> Things that needs to be checked . eg: is this resource in correct region? 

-> MAny policy definition combine to Policy initiative . Initiative is something which we are looking to achieve 


-> Thus we enforce policy definition, put it into an initiative and choose where you want to apply that scope 

a.3.2) Scope and Assign 

a.3.3) Assess Compliance 



a.4) Demonstration - Azure policy 
-> Assign a policy 
-> Create and assign an intiative definition 
-> Check for compliance 
-> Check for remediation tasks 
-> Remove your policy and initiative 

a.5) Azure policy: 

Azure Dashboard -> Policy 

-> Scope of subscription 
-> Overall resource compliance 
-> Resources by compliance state 

a.6) Blade one left in policy page;

Overview 
Getting started 
Compliance 
Remediation 
Events 

Authoring 
Definitions 
Assignments
Exemptions 


Here in Defintions -> We can define Policy and Initiatives 

-> Built in policies define common customer scenarios 

b) Thus azure policies is a way to put guard rails in place and ensure consistency across your environment
-> it can be technical control or something else 


7) AZ-104 Configure Role Based Access Control (6 of 31)
https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-6

Administer Governance and Compliance - Configure Role Based Access Control(RBAC) 

-> RBAC to define who should be able to do , what in your environment


Learning Objectives - RBAC 
1) Compare RBAC roles to Entra ID roles 
2) Create a Role definition 
3) Create Role assignment 
4) Apply RBAC authentication 

a) Compare RBAC roles to Entra ID roles 
-> RBAC roles provide fine-grained access management 

a.1) 
Azure RBAC roles 
1) Manage access to Azure resources 
ie Acces to subscriptions, resource groups and access to resources that live in those subscriptions  
2) Scope can be configured at multiple levels 
3) Role information can be accessed in the azure portal, Azure CLI, Azure Power shell, Azue Resource manager templates, Rest API 


Entra ID roles:
1) Manage access to Entra ID objects 
-> This is for management of users of devices of the internal components that make up your directory or tenant here. 
2) scope is at the tenant level 
3) Role information can be accessed in Azure portal, Microsoft 365 admin portal , microsoft graph, Microsoft graph powershell 
-> These roles used a lot in microsoft 365 space 

a.2) For both Entra ID roles and RBAC roles - there are many built in roles and we can create our own custom role 


b) Determine Azure RBAC roles :

b.1) RBAC role in Azure : Owner
-> Broadest permission and has full permission  
-> has full access to all resources and can delegate access to others 
-> service administrator and Co-administrators are assigned the owner role at subscription scope. This applies to all resource types 


b.2) RBAC role in Azure : Contributor 
-> one step below Owner 
-> Creates and manages all types of azure resources but cannot grant access to others 
-> This applies to all resource types 


b.3) RBAC role in Azure : Reader  
-> Views azure resources 
-> This applies to all resource types 

b.4) User Access Administrator
-> last access 
-> Manages user access to Azure resources 
-> This applies to managing access,rather than managing resources 

-> User Access Administrator + contributor = Owner 

c) Recommendation to have number of owners as minimum 

d.1) Creating Roles -> collection of permissions that lists the operations that can be performed.
i.e it contains a series of actions and not actions 

d.2) Create a Role assignment 
-> Process of binding a role definition to a user, group or service principal at a scope for the purpose of granting access. 

e) Entra ID admin roles -> Apply at tenant level 

Entra ID admin roles:
Global Admin 
Application Admin 
Application developer 
Billing Admin 

Azure RBAC roles:
Owner 
Contributor 
Reader 
User Access Admin 

-> While Azure RBAC roles can be applied any point below that 


f) Demonstration - Azure RBAC 
f.1) Locate Access Control blade 
f.2) Review role permissions 
f.3) Add a role assignment 

g) My Dashboard -> Search for "Resource groups" 

Resource Groups -> blade -> Access Control(IAM) 

-> Access Role based access control roles are also called as IAM roles 

g.1) Check Access /View Access / Role Assignments /Scope 

h) Recap:
-> Azure role based access control roles 
-> How roles function for giving you access to azure resources 
-> Recap on Entra ID roles 
https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-6 end 


8) AZ-104 Configure Azure Reources with Tools (7 of 31) - General administration of azure resources 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-7

-> You will learn how to select a tooling option such as Azure portal, Azure PowerShell, Azure CLI, or Azure Cloud Shell.

Learning Objectives:
Compare Administrative tools 
Demonstration - Azure portal 
Demonstration - Azure Cloud Shell 

a) Azure Portal 
-> View and manage resources 
-> Visual interface 
-> Unified hub - training and documentation 
-> Personalize your experience 
-> Mobile App 
-> Access the Cloud shell 
-> One off creation scenarios 

b) Azure Cloud shell
-> Interactive and browser accessible 
-> Offers Bash or powershell 
-> Authenticates automatically 
-> Provides on a per session and per user basis 
-> Temporary t- times out after 20 minutes 


c) Azure powershell and CLI 
-> Command line programs 
-> Interactive and scripting modes 
-> Cross platform 
-> Good for repeatable deployments 
-> Familiar coding experience 


d) Azure portal 
e) Azure Cloud shell 

-> My Dashboard -> Right side ... near accound -> Azure Cloud shell  

--> Cloud shell bash also there 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-7 - ends 

8.x) AZ-104 Configure Azure Resources with ARM Templates (8 of 31)  
https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-8

-> how to use Azure Resource Manager templates to consistently deploy assets.


Objectives:
-> Explore JSON template schema 
-> Explore json template Parameters 
-> Consider Azure Bicep files 
-> Demonstration - Quickstart templates 
-> Modify ARM template 
-> Deploy a template 
-> Save a deployment as an arm template 

a) Review ARM template Advantages:
-> Improves consistency and promotes reuse 
---> We begin with schema definition to get information on what is valid inside it 

-> Reduce manual, error prone and repetitive tasks
-> Express Complex deployments 
-> Expresss requirements through code 
-> Provides validatio tasks 
-> Modular and can be linked 
-> Simplifies Orchestration 

ARM Template (APP)
		|
		|
		|
		------------Development
		|
		|
		|
		------------Quality Assurance 
		|
		|
		|
		------------Production 	
		
-> We can have one common template to represent our app adn then use the respective parameters to deploy the application in consistent manner across all environments 
-> This helps to move infrastructure into code space. 

-
		
		
b) JSON template schema 

-> It defines all the Resource manager resources in a deployment 
--> Written in JSON 
-> Collection of Key value pairs 
-> Each key is a string 
-> Each value can be a string, number, Boolean expression, list of values, object 

-> Templates have a very consistent structure.
1) Schema 
 We begin with schema definition - Schema definition lets the template know where it needs to reach out to, in order to know what is valid inside the template definition 
 
 2) contentVersion -> What version you are upto with the template 
 3) parameters - things you like someone to change during execution of the template. 
 4) variables - things that change each time during the execution of template 
 5) functions - small pieces of code writtinen in json which we can execute continuously 
 6) resources - resources which we wish to deploy 
 7) outputs - if you have pipeline that takes infrastructure and is deploying it . We can set outputs to take output of deployment and pass it to the next part of a pipeline. 
 



{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "languageVersion": "",
  "contentVersion": "",
  "apiProfile": "",
  "definitions": { },
  "parameters": { },
  "variables": { },
  "functions": [ ],
  "resources": [ ], /* or "resources": { } with languageVersion 2.0 */
  "outputs": { }
}


-> 


c) JSON Template parameters 
-> Specifies which values are configurable when the template runs 





d) Azure Bicep files 
d.1)  Simpler syntax for writing template 


$ ARM templates are designed to be machine readable , which may be difficult for human to write. 
$ Azure bicep is alternative way to write and define your template as code. 

d.2) why is it called BICEP:
-> IT makes arm work , hence the name bicep :) 

-> Biceps allows you to compile BICEP into an ARM template at the end. 


-> Smaller module files you can reference from a main template 
-> Automatically detect dependencies between your resources 
-> Visual studio code extension with validation and intellisense 

eg:
param location string = resourceGroup().location
param storageAccountName string = 'toylaunch${uniqueString(resourceGroup().id)}'

resource storageAccount 'Microsoft.Storage/storageAccounts@2023-04-01' = {
  name: storageAccountName
  location: location
  sku: {
    name: 'Standard_LRS'
  }
  kind: 'StorageV2'
  properties: {
    accessTier: 'Hot'
  }
}



e) Azure code samples: https://learn.microsoft.com/en-us/samples/browse/?filter-products=azure
-> for example we choose Azure resource manager and if we search for Storage we will get them listed 

-> From here we can deploy where we can select Subscription-> Resource group  , Instance details -> Region  , account type, location etc  

-> All these things will be fed as parameters into template file 

f) Recap: 
f.1) ARM templates helps us to do : infrastructure as a code 
-> Define things what we wish to deploy in azure regardsless of complexity, how many times we need to deploy it or where we need to deploy it 
f.2) We can change parameters and ensure things are configurable 
f.3) We can also use bicep as easier mechanism for writing templates for arm 


Completing of https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-8 
 -> Azure Resource Manager templates 



9)  Configure Virtual networks 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-9

https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview

As part of virtual networks, we will see:
-> How Network functions in Azure and what the contituent components are: 
-> We will begin with dive into virtual networks , their configuration , their functions and how to set up etc 

Learning Objectives 
-> Plan Virutal networks 
- Create virtual networks 
-> Create Subnets 
-> Plan IP addressing 
-> Create Public IP addresses 
-> Associate Public IP addresses 
-> Allocate or Assign private IP addresses 
-> Demonstration - virutal networks 


a) Plan virtual networks 
a.1) 
-> Planning for virtual networks is one of the most critical things that you do as an administrator 
-> You understand the logical network that you have in your environment and how it interacts with other parts of the network. 
-> Having interactions between different parts of a network. 
		In our example On premises  needs to talk through to Azure environment  Or an Azure environment needs to talk to another Azure environment. In that case - we need to ensure that IPs dont overlap 
		-> it makes it easier when have disparate IP ranges that represent different parts of network environment. 
		



Virtual Network[With Subnet which has virtual machines with NICs) --------------------------> On Premises 
                                                                           |
																		   |
																		   |
																		   |
																		   ----------------> Virtual networks 


a.2) Virtual environment are utilized in a number of different ways - but the biggest thing that they have used so far is a place to home and attach network interface cards 
-> NICS are used to communicate in a private network. 
-> We need some place to home those private networks and so we can communiate across network lines 
-> NICs live within a subnet . The subnet contains a pools of IPs that each of those NICs can effectively pull an IP from . 
-> Subnet itself is contained within the virtual network 

a.3) Hence we can divide a virtual network into multiple subnets to reflect different parts of our logical network stack. 
-> Since network within Azure is all software defined, we can redefine this,add and grow over time, remove components of the network , stretch and pull it. 
---> Hence if virtual networks are planned well, then we can have plenty of network availability within the cloud 

b) Create Virtual networks :
-> Creating virtual networks is straightforward 
-> We need the flollwoing : 
	1) Resource Group in a region to home it 
	2) IP address space 
	-> There is a component in azure which helps to check for overlapping IP address 
	3) Subnet:
	Once we define IP address for the virtual network , we can go to each subnet and define what size they can be 
	---> A virtual network can be segmented into one or more subnets 
	-> Each subnet represents a different part of that logical network  
	-> how many ips can be there, what can we store there? 
	-> By default a default subnet is created, but you can name them anything you want

    3.1) Subnets can help improve security, increase performance, and make it easier to manage the network. 
    3.2) Each subnet must have unique address range - cannot overlap with other subnets in the vnet in subscription	
	4) No of available networks in ipv4: 10.0.1.0/24 or 10.0.2.0/24  is 251. This is two less than normal because:
	-> Because a virtual network subnet requires 3 IPs to function: .0, .1 and .255 
	5) .0,.1 and .255 are used for gateways, default gateways and also broadcast of addresses 
	6) In azure we need .2 ad .3 to handle DNS requests 
	-> This allows Azure resources to talk to one another in friendly manner and to know where each one sits 
	
	
c) Plan IP addressing: 


VNets, on-premises
networks, VPN gateways, <------Private IP---->Azure Resource<----Public IP Address----> Internet, public-facing services
ExpressRoute 				     Address

c.1) The planning we saw so far is, just for private IP space 
-> Private Ip addresses, - used within an Azure virtual network(VNet) and your on-premises network, when you use a VPN gateway or ExpressRoute circuite to extend your network to azure 
c.2) Virtual network contains private resources that are going to be in isolated environment and we can control how they want to communicate. 
c.3) On the other side, we have public Ips which is away to access resources that are located in azure environment via the Internet. 
- They are intended for public facing services 
-> Public IPs is a great way for opening a service to the broader internet 
-> Since it has security implication, we use public ip sparingly and only where we need to use them. 
-> it is important to include them in your planning process, because making use of these public IPs is critical for running modern enterprise applications. 

c.4) To create public IP we need to decide few things which are separate to virtual networks 
-> We need to decide where the public ip is going to be located , A region, SKU to be made use of , IP assignment whether static or dynamic 
c.5) How you want people to route to this IP. 
c.6) both iPv4 and IPv6 addresses are supported. 

d) Associate Public Addresses:
-> What can consume a public IP? 

d.1) A public IP address resource can be associated with virtual machine network interfaces, internet facing load balancers, VPN gateways and application gateways 

-> Below are common places that utilize public IPs 

Public IP addresses: Virtual  Machine, 			IP Address Association: NIC,                      		Dynamic: yes , 		Static: Yes 
Public IP addresses: Load Balancer,     		IP Address Association: Front-End configuration,  		Dynamic: yes , 		Static: Yes 
Public IP addresses: VPN Gateway: Gateway,		IP Address Association: Gateway configuration,  		Dynamic: yes , 		Static: Yes*
Public IP addresses: Application Gateway,		IP Address Association: Front-End configuration,  		Dynamic: yes , 		Static: Yes*


e) Allocate or Assign Private IP Addresses:

-> Below are common places that utilize private IPs 
Private IP addresses: Virtual  Machine, 				IP Address Association: NIC,                      		Dynamic: yes , 		Static: Yes 
Private IP addresses: Internal Load Balancer,     		IP Address Association: Front-End configuration,  		Dynamic: yes , 		Static: Yes 
Private IP addresses: Application Gateway,				IP Address Association: Front-End configuration,  		Dynamic: yes , 		Static: Yes


Dynamic(default): Azure assigns the next available unassigned or unreserved IP address in subnet's address range 

static: You select and assign any unassigned or unreserved IP address in the subnet's address range 


f) Demonstration:Virtual networks 

f.1)  Create a virtual network in portal 
-> Dashboard -> Virtual networks -> Create 
Following needs to be filled: 
1) Subscription, Resource group , Instance details like Virtual network name, region 
2) IP addresses eg : 10.0.0.0/16 
3) Add Subnet 
-> IP Address space, subnet details: Name, starting address, subnet size, IP address space. 
4) Review and Create and then Deploy 

f.2) Configure network security groups 
f.3) Configure Azure DNS 


g) Recap :
Virtual networks are a private IP address space 
-> Helps us to have our own internal network 
Public IPs available where we can connect outside to the public internet 


h) Link:
https://learn.microsoft.com/en-us/azure/virtual-network/manage-virtual-network


End of: https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-9


10) Configure Network Groups: https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-10
-> Module focusses on Administering Virtual networks 
-> In this module, we will be looking at a security control used in virtual networking called: Network Security Groups(NSGs) 
-> Also we will see, Application Security Groups for categorizing servers when it comes to private network traffic 

Learning Objectives:
Implement Network Security Groups 
Determine NSG rules 
Determine NSG effective rules 
Create NSG rules 
Implement Application Security Groups 
Demonstration NSGs 

a) NGS:
-> NSGs are extremely useful as a simple mechanism for allowing or denying traffic in your environment 
--> Using NSGs we can scope, what can talk to a server or an application in your environment 

a.1) NSGs are most commonly used at the subnet level 
-> By applying a NSG to a subnet within a virtual network, we can easily control what traffic flows in and out, using these allow and deny rules that check for IP , port and other things 
a.2) Allow or deny for both inbound and outbound traffic gives us nuanced control over our network scoping 
a.3) NSG does not have one to one relatioship with Subnet. 
-> A single NSG can associated to multiple subnets 
-> Thus we can define generic NSGs which can be later used across our environment.  
a.4) NSG can be applied at network interface level or NIC 


b) Determine NSG rules 
-> NSGs rely heavily on Rule set. 

b.1) Security rules in NSGs enable you to filter traffic that can flow in and out of virtual network subnets and network interfaces. 
b.2) There are default security rules. You cannot delete the default rules, but you can add other rules with a higher priority 
b.3) Security rules that start with 65 and have 5 digits are default security rules. 
-> While default security rules cannot be deleted, they can be overridden by creating with higher priority 
b.4) Any rules created by us within NSGS can be between: 100 and 4096 
b.5) Small the priority number, higher is the priority of the rule
b.6) By defining network security rules like this, we are determine what basic network infrastructure should be in our environment 
b.7) Default security rules present within virtual network helps in simple communications within a virtual network , communications with load balancer which is used internally in azure  and helps for things to communicate outbound to communicate outbound to the internet. 

b.7) Also default security rules, does not allow things that are behind NSG to allow inbound communication from the internet 
-> We need to set it up if we wanted to open it up by using public ip or something similar 


c) Determine NSG effective rules:
-> Because NSGs can be applied at two levels - we need to know how it functions internally 


c.1) How it works is: If we say that we wish to allow port 80 traffic through into the environment , we need to apply that rules in NSG2 and then again at NSG1 
-> We need to set allow rules at levels you apply NSGs 
c.2) This is one of the reasons why we suggest using NSGs as much as possible, only at the subnet  


c.3) NSGs are evaluated independently for subnet and NIC 
-> An "allow" rules must exist at both levels for traffic to be admitted 

c.4) There are some tools to assess the effective rules available against a single NIC within our network watcher toolset 
-> Use the effective rules link if you are not sure which security rules are being applied. 

d) Create NSG rules:

d.1) Source: is where the traffic comes from 
Source( Any, IP Addresses, My IP Address, Service Tags and application security grop) 

d.2) Destination: is where the traffic is headed to 
Destination(Any, IP Addresses, service tag and application security group) 

d.3) Service - What service you are utilizing 

Service(HTTPS, SSH, RDP, DNS, POP3, custom...) 

d.4) 
Priority - Lower the number, higher the priority 


d.5) Rules can be set both at the inbound and outbound traffic 

e) Implement Application Security Groups 

SERVICE TAGS: 
e.1) In virtual networks there is a concept called service tagging 
-> This is where we say: Traffic headed towards load balancers - in that case Service tag of "Load balancer" will be applied to it. 

--> Service Tags are defined by the microsoft platform. No custom service tag could be created 

e.2) Application security groups helps you to define a set of servers with a role and then we can use it like a service tag 
-> like saying all webservers should have traffic allowed for web based traffic 
-> All AppLServers should have configuration to allow traffic so that it can talk to databases(1433) 

Source						Destination					Port
Internet					Webservers                  80,443 
Webservers                  SQLServers					1433



Internet ---------> Webservers----------->AppLServers 



e.3) We can use one common network security group  which reflects both sets of conditions 
e.4) ASGs allow us to logically group our virtual machines in a network layer. 

-----<Combining principles of Network security groups with a bit of custom abiltity based on roles and logical structure of your application 


f) Demonstration: 
Create a network Securit Group 
Explore inbound and outbound rules 

Azure Dashboard -> "Search" Network Security Group -> 

1) Basics -> Subscription/Resource group , Instance details, Name /Region 
2) Tags 
3) Review + Create 


4) Once NSG is created, we can define our inbound and outbound rule set, so that we can control where things need to flow  

Network Security Group -> Settings -> Inbound security rules / Outbound security rules , Network Interfaces, Subnets , properties 

-> Associate rules to subnets for particular virtual network 



g) Recap:
-> Network security group helps us to check traffic as it passes through at the submit or network interface card level 
-> THen simply say whether it should or should not be allowed to pass 
-> NSGs are versatile and used all over the environment 


h) https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview  

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-10  end 


11) AZ-104T00A - Azure DNS - Administer Virtual networking 
-> Learn how to configure Azure DNS including custom domain names and record sets.

Learning Objectives:
● Identify Domains and Custom Domains 
● Verify Custom Domain Names 
● Create Azure DNS Zones 
● Delegate DNS Domains 
● Add DNS record sets 
● Plan for private DNS zones 
● Determine private Zone uses 
● Demonstration - DNS Name Resolution 

a) Identify Domains and Custom Domains 

-> When you create a new Entra ID tenant, a new default domain is created 
-> The domain has initial domain in the form: domainname.onmicrosoft.com . This domain sits in the backend and is associated to your Entra ID directory 
-> You can customize/change the name 
-> After the custom name is added, it must be verified - this demonstrates ownership of the domain 

b) Verify Custom Domain names: 
-> Verification demonstrates ownership of domain name 
-> Add a DNS record(MX or TXT) that is provided by Azure into your company's DNS zone 

eg: 
  -> In the DNS provider, we need to add: "Destination or points to address": MS=ms9094380 
   --> This is a unique ID and needs to be added in side of DNS provider 



-> Azure will query DNS domain for the presence of the record. 
-> This could take several minutes or several hours 

b.1) Associating custom domain name to a Tenant is a one to one relationship 
-> if you wish to use this domain for other Entra ID Tenant, we will need to go through and deregister it first.  



c) Create Azure DNS zones :
c.1) A DNS zone hosts the DNS records for a domain 
-> If we have custom domain in place, we have the ability to host DNS records. 


c.2) When multiple zones share the same name, each instance is assigned different name server addresses. 

c.3) Root/Parent domain is registered at the registrar and pointed to Azure NS 


d) Delegate DNS domains

d.1) When delegating a domain to Azure DNS, you must use the name server names provded by Azure DNS - use all 4. 
d.2) Once DNS zone is created, update hte parent registrar. 


d.3) For child zones, register the NS records in the parent domain 



e) Add DNS record sets:
e.1) A record set is a collection of records in zone that have same and are the  same type 
e.2) You can add upto 20 records to any record set  
A record set indicates all the addresses to which we want to have shorthands 
e.3) A record set cannot contain two identical records 
e.4) Changing drop down type, changes information required. 

f) Plan for private DNS zones 
-> Private DNS zones allow us to have resources within Azure. 


(VM1)---------Request to db.contoso.lab----->Azure Dns 
  <------------Respond with private IP----
  ------Connect to resource withprivate IP----->VM SQL server 
  
f.1) Request reaches to Azure DNS 
f.2) Azure DNS responds with private IP 
f.3) Connect to resource i.e SQL server with private IP 

-> This is doing name resolution without having to spin up a big DNS solution and full available across Azure environment 


f) Determine private Zone scenarios 
g) Demonstration  - DNS 
g.1) Create a DNS zone 

Dashboard -> Search DNS Zones 

DNS Zones for public infrastructure and Private DNS Zones used for internal registration 

Create DNS Zone -> Basics /Subscription/Resource group, Instance Details /Name, 

->We cannot select Resource group location because DNS is a global service , so they are deployed to all regions simultaneously , to ensure 100% SLA 
-> Then review and create 
g.2) Add a DNS record set 
-> 4 name servers will be listed in your DNS zone 
-> Different types of records can be selected while adding record set. 

Name/Type /Alias Record set /TTL/TTL unit /IP address 


g.3) View the name servers 

h) Recap 
-> DNS comes in two flavours : public facing used for websites , useful for people accessing components of your environment where we want them come via friendly name. 
-> private DNS zone - useful when we want to redirect things internally in our virtual networks 


https://learn.microsoft.com/en-us/azure/dns/dns-overview


g.4) https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-11 end 


12) AZ-104 Configure VNET peering (12 of 31) - Administer Intersite Connectivity 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-12 


-> Learn to configure an Azure Virtual Network peering connection and address transit and connectivity concerns.

--> Intersite connectivity  means mechanisms for connecting one component of azure to somewhere else.
-> In this module our focus will be on Virtual network peering or Vnet peering 




->  VNET peering is a way for two disparate virtual networks to create an internlink between one another. 
-> It may be unidirectional or bidirectional in order to establish direct pathway communication across the microsoft backbone network 




Learning Objectives:
-> Determine VNet peering uses 
-> Determine Gateway Transit and connectivity needs 
-> Create VNet Peering 
-> Determine Service chaining uses 
-> Demonstration - VNet Peering 

a) Where and why we use VNet Peering : 
a.1) If you have two virtual networks in azure, no matter where they are located( same region or in different regions)  , it allows you to establish isolated connectivity between them 
-> Thus we have an easy seamless ability to establish regional pairing to allow these two virtual networks  to communicate as if they are one. 
  eg: VNet 2 and VNet 3
  
-> Or  for connecting Globally between regions VNet1 and VNet2 



[Region 1 [VNet1]]<---Global VNet Peering--->[Region2 [VNET2]<---Regional VNet Peering---->[VNet3]]

a.2)
-> Simple set up 
-> It runs on whatever rate we get out of the microsoft backbone. Hence extremely fast. 

a.3) Virtual networks needs be in same subscription. 

a.4) Virtual networks in different tenants can be Peered

a.5) Hence VNet peering is interesting mechanism for linking one azure environment controlled by one company to another Azure environment of another  company. 


b) VNet Peering Uses:
b.1) VNet peering should be goto choice for interlinking two virtual networks 

b.2) Two types of peering - Global and regional 
b.3) Connects two azure virtual networks - You can peero across subscriptions and tenants 
b.4) Peered networks use the azure backbone for privacy and isolation 
b.5) Easy to setup, seamless data transfers and great performance 


c) Determine Gateway transit and connectivity needs 
c.1) Two main ways that VNet peering gets utilized 


d) WAY 1: Peering for HUB
-> If there are virtual networks  VNet A, VNetB and if we want to communicate back to our hub Virtual network  which is in Hub and Spoke architectural model - peering is key to ensure here. 


[VNET A]<--------->HUB<-------------[VNET B]

d.1) Peering is key to ensure that the hub, where our core resources and shared resources are stored , can connect to the spokes where our application is going to live. 

d.2) This helps us to select what traffic we wish to allow across the pathway between hub and spoke. 
-> This means that we can have things like virtual machines on VNet A must traverse to the hub and pass through a firewall for analysis 
-> Peering enables this in a simple manner and centralize some of the big key network resources  



e) WAY 2: Gateway transit :
-> Here we have VNet A on left and VNet B on right side. 

-> HEre VNet B wants to talk back to an ON premises environment . Lets consider we have a VPN connection which helps for connectivity across the public internet  encrypted between Hub and On premises location 

-> But we want to ensure that only few tunnels are established which helps to reduce the security profile and also keep the blast radius low.

e.1) Thus by peering, we can have a simple check where we tell VNet B to use the remote gateway whatever it is peered to  and we tell hub to allow gateway transit. 

e.2) By doing this, our virtual machine located in VNet B can easily communicate back to on-premises resources using that one common gateway.

e.3) By default, VNet peering is able to be a fully open pathway . But it is also configurable in both directions. 

-> Thus gateway transit allows peered networks to share the gateway and get access to the resources 
-> No VPN gateway is required in peered spoke virtual network 
-> Default VNet peering provides full connectivity 



f) Biggest thing to know about peering : is that IP addresses between these virtual networks cannot overlap 

-> if they share an ip address space, then VNet peering wont be done. 


g) Create VNet peering: Major options 

g.1) Option1: Traffic to remote virtual network 

If we wish to allow traffic to remote virtual network . So, if i am going from VNet A through to B  and if we establish a peer in direction of B 

-> Do we wish to allow A to talk to B? 

A---->B<-----C 

g.2) Option2: Traffic forwarded from remote virtual network 

so if we have VNet C and it wants to talk to B ,  Should B be able to send traffice on to A? 

SO the question is: Can  i use B as a pathway to get to other virtual networks 


g.3) Option3: Remote Virtual network  Gateway 

-> If we dont have any gateway , the default is NOne
-> But if B is where your VPN sits, back to On-prem  we can tell A to use that location there. 


h) Determine Service Chainging Uses:
h.1) With regards to traffic forwarded from remote virtual network , if we chose to have a  hub and spoke model -- Where the hub contains core resources and spokes contain our apps. 
-> Using forwarding components we can have three passed to the hub , a firewall does the analaysis  and then if traffic is allowed, we can go on to remote virtual network.   


HUB Vnet[Network virtual appliance or VPN gateway <-------> VNet2 
													|
													|
													------>VNet3 
 


h.2) Thus we can use this principle of Chain to ensure that core resources are shared amongst the network 
h.3) by this way,it is ensured that  all important resources , all rules and security components are in single location and thereafter use it as communication path between them 

i) Demonstration of VNet peering 
i.1) Configure VNet peering on first virtual network 
  -> Configure VNet peering on second virtual network. 
  
i.2) Go to azure dashboard -> Search for Virtual network 

j) Recap:
-> To interlink to virtual networks together - the easiest ,simplest, fastest and with least maintenance way is via: VNet Peer  
-> For two virtual networks in azure to communicate with one another, we should use VNet peer 



https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-12  end 



13) AZ-104 Configure Network Routing and Endpoints (13 of 31) 

AZ-104T00A - Intersite connectivity 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-13

-> Learn to configure network routes including endpoints and private links 
-> i.e Configure Network Routing and Endpoints 
---> Endpoints offer different ways to route traffic in azure and 

Learning Objectives:
-> Review System routes 
-> Identify User-defined Routes 
-> Demonstration - Custom routing tables 
-> Determine Service Endpoint Uses 
-> Identify Private Link Uses 

a) Review system routes 
-> We got environment set up and did not make any changes . We have our first virtual network 
-> This virtual network has two subnets . One for the front end traffic where our website sits and one for the backend where our backend processing virtual machines sit 

a.1) Default behaviour of System routes;
-> By Default, things in frontend subnet that have a public ip will be able to have traffic flowing in from the internet and reach those web servers 
-> In addition, they will also be able to reach out to the internet, because they should be able to talk to internet to get patching and other updates 
-> Also subnets can freely communicate to one another as a default system route. 

--> hence things in backend and things in front end are able to talk to one another with no extra configuration required. 

a.2) Following are allowed as part of default system routes 

     Traffic between VMs in same subnet. 
     Between VMS in different subnetss in same Virtual network 
	 Data flow from VMs to the internet 
	 Communication between VMs using a VNet-to-VNet VPN 
	 .....
	 An ExpressRoute circuit represents a logical connection between your on-premises infrastructure and Microsoft cloud services, and it's deployed with either a connectivity provider or ExpressRoute Direct. You'll need to use an ExpressRoute circuit with any combination of ExpressRoute offerings.
	 .....
	 
	 Site-to-Site and ExpressRoute communication through the VPN gateway 
	 
a.3) To change something in system routes , it comes to the routing table 

a.4) Route tables are an object that we can create in Azure and have user defined routes 


B) Identify user defined routes 
-> Route table consists of a set of rules called routes, which specify how packet should be routed in a virtual network 
-> User-defined routes are custom routes that control network traffic by defining routes that specify the next hop of the traffic flow 

b.1) route Table effectively contains a list of next hops

-> The next hop can be a virtual network gateway, virtual network, internet of virtual appliance.

-> In layman terms each next hop represents: if i have to come to this place, where do i go first  

b.2) Consider an example where our front end configuration has a user defined route(UDR) that says: If my next hop is internet - the user defined route , forces the traffic to go through a firewall at the edge for analysis. 

-> Thus a UDR allows us to configure firewall inspection on the way out at the door


b.3) The frontend subnet and backend subnet need to communicate one another 
-> But because we are changing things from: things that general users can see from internet  to things that are internal to our network - we should inspect that traffic through inspection device: VM/Application IP forwarding
-> In that case create a UDR if front end wants to talk to backend , then it again needs to pass through the inspection device: VM/Application IP forwarding
                                        Internet 
											|
											|
  User defined Route-----VM/Appliciance------
      |                   IP forwarding 
      |
      |
[frontend subnet]---systemroute----[backend subnet]
      |                                     ↑
	  |                                     |
	User Defined Route----VM/Appliance--------
	
	
b.4) Passing through firewall is not the only thing we can do with UDR 
-> But it is the most common and simple thing we can do with UDR , to ensure the traffic flows where we are expecting 


b.5) In UDR -> Next hops we can configure individual arbitrary IPs, virtual networks , internet and individual virtual appliances 

b.6) Demonstration - Custom Routing Tables 
-> Create Route Table 
-> Add a Route 
-> Associate a route table to a subnet. 

-> In Azure Portal ->Dashboard ->Search "Route tables" and create route table with following details :

Project Details: Subscription , Resource group 
Instance Details : Region, Name , Propagate gateway routes 

-> Ability to chose whether you wish gateway routes to be propagated or not. If you want to create a route table that will not route people to an On-Premises location it is possible to do so using this option: Propagate gateway routes 

b.7) Then after entering basic details we can do: Review + create . Route tables will be created and then we can define routes for route table 


b.8) General principle how route tables function:
Principle1: More specific route will win 
eg: if you tell that i can hop to one IP and i only want to pick that, if i am going to one IP address - I will take that above something that says i want to capture  a broad range of IPs. 

Principle2: The more specific a route is i.e less number of IPs that are covered by it , the more likely we are to take it and treat it as higher priority 


b.9) In the Route Table created -> Routes -> Add

-> This will create UDRs with following parameters 

Route Name 
Destination Type: Either Service tag or set of IPs 
Destination IP Addresses/CIDR ranges : eg: 192.168.0.0/24
Next Hop Type : Virtual appliance or gateway 
Next Hop Address : give an ip here :192.68.1.1


b.9) Breakdown of above User defined route(UDR) 
-> if i am requesting an IP of 192.168.0.0/24 which is a block of 256 IPs , then i need to instead forward the traffic across to my firewall located in 192.168.1.1 

-> This allows us to override those default system routes, by allowing it to filter the traffic through an appliance. 


c) Type of Routes available: 

c.1) Catch all Route: Do it when it was not caught in any of the user defined routes, this will be the fallback route 


Route Name : All-To-Internet 
Destination Type: IP addresses 
Destination IP Addresses/CIDR ranges : eg: 0.0.0.0/0
-> By mentioning this we mean every possible IP under the sun 
-> So we are checking for any traffic that does not match one of the more specific routes in my route table, we can choose that the next hop can be internet 
Next Hop Type : Internet 
Next Hop Address : give an ip here :192.68.1.1

-> By doing this catch-all-route, we ensure that we never default back to system routes that azure provides because we have given something as a fallback here. 


c.2) Alternative to All-To-Internet 
-> By doing a Blackhole Route we can achieve it
-> if traffic does not match any of the user defined routes , then send the next hop as none and drop the traffic 

Route Name : Blackhole 
Destination Type: IP addresses
Destination IP Addresses/CIDR ranges : eg: 0.0.0.0/0
Next Hop Type : None 
Next Hop Address : 

-> Setting like this can have impact,where we say drop the traffic, if the traffic does not match any of the rules here 
-> This helps in allowing traffic only which you recognize 


d) Setting up UDRs are specially useful in 
Hub Spoke virtual network model with peering because we can then force traffic to pass through to the hub if someone wants to communicate with secondary spoke 

e) Associate a route table to a subnet 

Once we have our routes in place , next we need to make the subnet effective. 


-> Here in routing table we select subnet and specify which subnet requires this new routing table to be put in place 

In Dashboard -> Route Table -> Subnets -> Associate -> Virtual network and Subnet 

-> By selecting a subnet, all traffic in that subnet will refer to these routes instead of Azure default system routes 


f) Determine service endpoint uses 
f.1) We have couple of alternatives or additions to routing table. 
-> first is the service endpoint. 

f.2) Service endpoints are an optimization pathway that allows resources in a  virtual network to communicate directly to Azure resources that we are hosting as a managed service

eg: We have a virtual machine located in subnet. We want this virtual machine reach out to a storage account in order to go and get some files from the storage account. 

-> Default behaviour will be that: This virtual machine leaves the subnet . The subnet leads to the virtual network . The virtual network tries to go out to internet 
-> Azure recognizes it as an internal component and then it will redirect accorss to that storage account 



Virtual machine ---> Subnet --> Virtual network ---> Internet ---> Azure recognizes it as internal component ----> Redirects to storage account. 


---> In this flow we have a lot of hops. 


g) We will make it more efficient by enabling a service endpoint for the particular microsoft service you wish to access. In our case the microsoft service is Microsoft storage. 

-> All storage accounts can be accessed via an optimized pathway that goes straight from the subnet 

-> Thus by having service endpoint, we will have significantly less hops and extremely fast service 

-> This is also secure 

g.1) If it is an optimization pathway , how will it be more secure? 
-> This is because of the secondary component to a service endpoint. 

-> When you configure one, each of the services you see in service end point, will additionally have ability to add firewall rules to allow access from specific virtual networks or IP ranges. 

g.2) Thus we can put a rule that says : If i am not coming from the subnet that i am expecting the traffic from , we can deny that traffic. 
-> We can prevent people even with correct authentication and authorization attempting to come from the general internet , from accessing any files in your storage account 



Virtual Machine -> Subnet-->Virtual network ---> Service Endpoint ----> Storage account 


13.1) Identify Private link uses: 

If a service endpoint is focused on this optimized pathway - what do we have in terms of isolation ? That would be: private link 


a) How private link works:
-> Private link acts as middleman that goes from a private endpoint. 
--> A Network interface card that we deploy into our virtual network through to a single instance of a managed service in Azure. 

eg: Here its database. 

-> There are many situations where legacy applications expect SQL db to be on a local IP 

b) By utilizing private link service we can tell these compute resources to access this database which is on on premises or peered network 



 

[NSG:Compute]---> [NSG:private endpoint]-----Azure Private link ---------> SQL + SQL +SQL 
                           |                                                  |
						   |                                                  |
						   |---------------------------------------------------
						   
						   
c) 
.....
Private connectivity to services on Azure. Traffic remains on Microsoft network with no public internet access 
Integration with on-premises and peered networks 
In the event of a security incident within your network, only the mapped resource would be accessible. 
.....

d) This private link is a significantly smaller way of reducing blast radius and isolating access to very specific resources 

e) In above scenario, in order to access the database, we need to go through the private endpoint and Private link service does all the magic in between  

f) This allows to completely disable public internet access and only allow access to databases and resources that support private link directly from this one private endpoint 

g) Thus if we are loooking for security in isolation method, then we can look for private link service 

g.1) Private end points ensure that traffic is only accessed from a single private location 

h) Recap:
h.1) 3 different ways to control network routing
  UDR or Service End points  or Private Link Service 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-13  - end 


14) AZ-104 Configure Azure Load Balancer (14 of 31) 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-14

AZ-104T00A - Administer Network Traffic - Load Balancing 


->  Loadbalancing is the ability to take a single input point and then be able to subdivide traffic into multiple output points 
-> It is extremely useful if we are using scalable service or if we are using multiple service that we need traffic to redirect 

a) Configure Azure load balancer : Introduction 

Topics/Learning objective:
-> Choose a load balancer solution 
-> Implement a Public load balancer 
-> Implement an internal load balancer 
-> Determine load balancer SKUs 
-> Create Load balancer rules 
-> Demonstration - Configure a load balancer 
-> Learning recap


b) Choosing a Load balancer Solution: 
-> How do we pick the correct load balancer solution 

b.1) Whether you need to pick a regional service operating in only azure region Or Something that needs to be delivered globally 


.........
Application Gateway vs Load Balancer 

Application Gateway: It optimizes delivery from application server farms while increasing application security with web application firewall 


Load Balancer: Balance inbound and outbound connections and requests to our application or server endpoints


.................


b.2) Two regional services are: Application gateway and Azure Load balancer. 
-> Between those two, how do we decide that Load balancer is our product of choice  
-> It all depends on protocols 

b.3) If you are using TCP or UDP packets, then that is a layer for load balancer 
-> Load balancer works great for web applications, general applications and variety of placess where we require single input redirected to  multiple outputs
-> We use it extensively for redirection in internal applications and ensuring  balancing for a range of different solutions 

c) Implementing a public load balancers 
-> Maps public IP addresses and port number of incoming traffic to VM's private address and port number and vice versa. 
-> Apply load balancing rules to distribute traffic across VMs or services. 

c.1) it is called public load balancer because at the front it, it has a public IP 


                 ....General users....
						   |
						   |
						TCP Port 80
						   |
						   |
						   |
		Load balancer----> with Public IP 
		                   |
						   |
						   |
		-----------------------------------------
		| 					|					|
		|					|					|
		80					80					80
		|					|					|
		|					|					|
	   VM					VM                  VM    
                           						   
												   
c.2) We are able to configure this public IP to allow general users in whatever mechanism you choose for authentication , to be able to go across the internet through to that public IP endpoint - Then load balancer will distribute traffic to the backend machines to ensure that things stay up 

c.3) Whats great about this is: No public IP is required for any of those backend virtual machines 
-> We can have only one Public Ip and then a load balancer acts as one input distribution point for our backend servers 

c.4) How do we decide that when traffic arrives at front, then it goes to the servers in the back 

d) To check that, lets check at the alternative - which is the Internal Load balancers 
->  Internal load balancer is named so because instead of public IP , it has a private IP at its front end 


                   Private IPs 
   VM              VM              VM 
   |				|				|
   |				|				|
   -----------------------------------
                    |
					|
		 Internal Load balancer
					|
					|
	-----------------------------------
	|				|					|
	|				|					|
	1433			1433				1433
	|				|					|
	|				|					|
  ----------------------------------------
  |					|					|
  |					|					|
  SQL 				SQL 				SQL 
  
  
d.1) In this case, we take traffic from the VM and redirect them to our database tier in the backend 
-> This is useful because we can have multiple layers of scalability for our application representing different tiers of an app 

-> if we add a public load balancer on the front before the VMs where users come from the front, then it is known as two tier web app 

d.2) Mutlitier applications with load balancers in between each layer are extremely common and it is a great way to ensure performative action across each one of these layers , where they can individually scale and meet the deman that is required for its specific purpose 

			External Users
					|
					|
            Load balancer with public IP 
				   |
                   |

   VM              VM              VM 
   |				|				|
   |				|				|
   -----------------------------------
                    |
					|
		 Internal Load balancer
					|
					|
	-----------------------------------
	|				|					|
	|				|					|
	1433			1433				1433
	|				|					|
	|				|					|
  ----------------------------------------
  |					|					|
  |					|					|
  SQL 				SQL 				SQL 
  





e) Determine Load Balancer SKUs 
-> Load balancer apart from being able to configure different IPs at the front end like public or private, it also has a SKU configuration 
-> These SKUs represent different T shirt sizes 

-> Here Basic SKU is free service and Standard SKU is paid 

Backend Pool Size:
-> More versatility in terms of number of instances in backend. 
Basic SKU: 300 IP configurations, single availability set 
Standard SKU: Upto 5000 instances 

Secure By default: 
Basic SKU: by default open to internet 
Standard SKU: Closed to inbound connections unless opened by NSGs 


SLA: 
Basic SKU: Not Available 
Standard SKU: 99.9% 


e.1) Basic SKU only for sandpit environments and basic testing 

e.2) For any major workload, we need standard sku 


f) Create Load Balancer rules 
-> Configuration that we need put in place, to ensure that when a client comes to the front end - they are able to reach the thing they need in backend 

-> What does it look like, when we define these load balancing rules 
  
  
Client<----Inbound connection---->Frontend ip address(Public or private loadbalancer)<----Load balancing rule---
				|
				|
			Virtual Machines 
			
----------------------
Load balancer rules maps a front end IP and port combination to a set of backend pool and port combination 

Rules can be combined with NAT rules 

A NAT rule is explicitly attached to a VM(or network interface) to complete the path to target 

---------------
			
What all should be defined in rules: 			
f.1) There will be a front end IP address. 
f.2) We need to define a rule that says, what behaviour we are expecting which is usually done by a port in an IP because: port says the service 
f.3) Backend pool: So the virtual machines can be grouped together in a backend pool , that represents everything that we need to redirect to 
f.4) This is how we define one rule, that directs traffic amongs multiple different endpoints within a backend 

f.5) Rules can be combined in a different ways 
f.6) one way is the: Network address translation rules or NAT . NAT allows us to set a specific rule where if someone goes with a specific port/IP combination , we can ensure that they always go to one of these particular virtual machines 



g) Demonstration - Configure a load balancer 

Portal - Helps me choose a load balancer 
Configure a load balancer(review settings) 

g.1) In azure portal-> Dashboard-> Search"Load balancer" 

-> There will be two things:
Load Balancers 
Load Balancing - help me choose 
-> This has a decision tree which helps us to choose correct load balancer for your specific application 


g.1) it helps us to choose any of 4 load balancing services :
1) Application Gateway 
2) Front Door and CDN profiles 
3) Load Balancer (Layer 4 load balancer) 
4) Traffic Manager 


g.2) Some configurations to choose for load balancer :

g.3) 
1) Basic
Project Details:
Subscription/Resource group 

Instance Details:
Name /Region/SKU /Type/Tier 


2) Frontend IP configuration:

-> Add Frontend ip configuration /Name/Subnet/Assignment/Availability zone 

3) Backend Pools 

Name/Virtual network /Backend pool configuration/IP configuration/IP addresses 


4) Inbound rules / Outbound rules 
-> Define where traffic should be sent and why it gets sent to each location 

Loadbalancing Rules -> Name/IP Version/Front End IP Address/ Backend pool / High availability ports/ Protocol/ Backend port/ Health probe/ Session Persistence/Idle timeout/Enable TCP reset/ Enable floating IP  

-> Health probes allows us to easily check things in backend and make sure that end points are actually up and running 


g.2) What is session persistence: 


Session helps to say: if a user sends one request , we will send the request to whatever virtual machine is available . Then if they come back , do they need to go to same virtual machine or can they just go to some one else in the pool? It is our call 
-> By selecting client IP as my session persistence earlier , i can ensure that a client coming through on same ip address goes to same virtual machine in the backend 
-> If the virtual machine is not available in backend, we support DRAINING to ensure that , connections are moved to the next available virtual machine  

g.3) In addition, we also support client IP and protocol - so you can have only specific protocol requests from the same client, go to the same virtual machine 


Session Persistence options: None/ClientIP/Client IP and protocol



h) Recap:
-> Azure load balancer is the one of the most straightforward and frequently used balancing options for traffic in Azure 
-> It is able to take traffic from a public IP or private IP and redirect it in your environment to a pool of backend  endpoints or servers 
-> It is great way to ensure that, each tier of an application can scale independently, run in a performative  manner  and do what it needs to do  


https://learn.mic-end rosoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-14 -end 



15) AZ-104 Configure Azure Application Gateway (15 of 31) 

AZ-104T00A - Administer Network Traffic
 https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-15
 
 -> Learn how to configure Azure Application Gateway.


App Gateway is a great way to take traffic in, that is intended for a web application and then be able to redirect it to back-end pools of servers or endpoints in order to get people where they need to go. 

Learning Objectives - Configure Azure Application Gateway :
Implement application gateway 
Determine Application gateway routing 
Demonstration - Configure an Application gateway 
Setup Application gateway components 



a) Application Gateway functions:
-> Manages web app requests 
-> Routes traffic to a pool of web servers based on url of a request 

-> Webservers can be azure VMs, Azure Vm scale sets, Azure app service and even on-premise servers  


 
b) Application Gateway Work Flow :



Browser----ApplicationGateway---Http/Https Listener---->Rule/ Http Setting ----Pool[VM/VMSS/ Servers]

b.1) Application gateway is designed to receive traffic requests from users that are making use of a browser and then it is able to redirect those via a listener  
b.2) Listener sits in the middle and it is able to dissect the requests that a user sends through, try and get a bit of context  
b.3) Then based on the rules we have, we can redirect users to individual virtual machines, scale sets of virtul machines, or endpoints located in other locations, including on premises 
b.4) it is great way to redirect portions of website or to add extra layers of security or filtering or error messaging without actually redeveloping an application 

c) Determine Application Gateway Routing 
-> Lets look at different routing options 

-> Application gateways operate at layer7 of the network stack, which means that we are interested in URL that someone is trying to visit and will change where they end up based on that URL.

c.1) We have two options for routing within an application gateway. The two options are based on 

1)Option1: Path based routing: Portion of a url after the initial domain 


Users <---contoso.com---->ApplicationGateway[WAF/L7 LB]---/images/*-----> Imageserver pool or Video Server pool  

->  Here contoso.com is where people get redirected to the app gateway , if they request an image, it will be sent to image server pool and if they request video, they will be sent to Video server pool. 

-> This is all done based on the rules we put in place for Application Gateway Routing 

2) Option2: Multiple-site Routing 
-> We can effectivly have a single input point 


Users <-----> ApplicationGateway/WAF/L7 LB ---contoso.com----> Contoso pool 
                                            |
											|
											\--fabrikam.com---> Fabrikam pool 


-> Here when users hit a site, they will reach a public ip , users for different sites will access this one end point here 
-> Based on the site requests, they do - we redirect them to different websites in the backend 
-> Users of contoso.com and fabrikam.com will have one public ip, they talk to - based on what they ask for, we send them to the right place  
-> Both of these are extremely useful 


d) WAF : Web application firewall 
-> It is a security filtering and monitoring tool, that allows you to inspect the traffic  of users, as they send requests to your website and understand if they represent a potential threat 
-> We use threat modelling under the OWASP framework  to be able to analyse what is coming through in terms of that security request 


e) Demonstration - Configure an Azure Application Gateway 
-> COnfigure azure application gateway 
-> Compare to the load balancer 

e.1) Azure application gateway is different than other load balancing options that we have. 
e.2) In Azure portal -> Create Application Gateway 

BAsics: 
1) Project Details -> Subscription / Resource group 
2) Instance Details -> Application gateway name/region/Tier/ Enable autoscaling/ minimum instance count / Maximum instance count /  
3) Configure virtual network / Virtual network /Subnet

4) Front Ends:
Front End IP address type 
Public IP address 

5) Backends : This is configuring where we want to send things in backend 
Add backend pool-> Name/ B

6) configuration / Add Routing Rules 
-> Routing rules helps to link Front ends with Backend pools 

Add a routing rule -> Rule Name/Priority/Listener -> Listenery name/frontend ip protocol/port 



Rule Name/Priority/Backend Targets / Backend pools/redirection 

f) Recap:
Azure application gateway offers a mechanism to take traffic that is coming from a user who is attempting to reach a particular website and redirect them accordingly 
-> We have methods for redirection 
-> Methods for adding additional pages for erros 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-15 end 


16) AZ-104 Network Watcher (16 of 31)
https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-15 start 

You learn how to configure Network Watcher and troubleshoot common networking problems.

AZ-104T00A - Administer Network Traffic


Learning objectives : Configure network watcher 
Describe network watcher features 
Review IP flow verify diagnostics 
Review next hop diagnostics 
visualize the network topology 


a) Describe Network watcher features 
-> A regional service with various network diagnostics 

a.1) IP flow verify: diagnoses connectivity issues 
a.2) Next hop: Determines if network traffic is being correctly routed  and monitoring tools 
a.3) Flow logs : maps IP traffic through a network secuirty group 
a.4) Connection troublesheet:shows connectivity between soure vm and destination 
a.5) Toppology : generates a visual diagram of resources 


b) Monitoring: topology 
			   Connection monitor 
			   Network performance monitor 
			   
			   Network diagnostic tools: 
			   Ip Flow verify 
			   NSG diagnostics 
			   Next hop 
			   Effective security rules 
			   VPN troubleshoot
			   Packet capture 
			   Connection Troubleshoot 
			   
			   Metrics: 
			   Usage+quotas 
			   
			   Logs:
			   Flow logs 
			   Diagnostic logs 
			   Traffic analaytics 
			   
			   
c) Review IP FLOW VERIFY Diagnostics 
-> It helps to do a simple check: We choose a protocol , choose a direction inbound or outbound, local ip/local port and Remote ip and Remote port 
-> it will tell what NSG is preventing or allowing that traffic to flow 
-> It helps to identify where a rule is altering your environment 
-> if we want to see, where traffic is being dropped  then we can use:  IP flow Verify 

d) Review Next hop Diagnostics:
-> This is interested in your route tables, where we define user defined routes 
-> We set UDR to change how network traffic flows in your environment. 
-> Next Hop diagnostics tells if a system route is applied to your environent where your traffic has flowed 
-> or if a route table is in place , which specific route table is controlling, how things have hopped. 
-> it also helps to find, where you traffic is actually going in your environment 

-> Next hop diagnostics does not require you to remote into a virtual machine . You just need to have permissions to the portal

e) Vizualize network topology 
-> provides visual representation of your networking elements 
-> View all the resources in a virtual network, resource to resource asssociations and relationships between resources 

-> We can select a virtual network and see all th resources present 


f) Recap
-> Ran through top 3 network watcher tools for azure administrators 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-16 end 

17) AZ-104 Configure Storage Accounts (17 of 31)

Learn how to configure storage accounts, including replication and endpoints.

-> Storage account is the primary way we store data in azure, either it be logging data required by Virtual machines or for data you bring to the cloud. 
-> We can have many different types of storage 

Learning Objectives:
Explore Azure storage services 
Determine storage account kinds 
Determine replication strategies 
Access storage 
Secure Storage endpoints 
Demonstration - Configure a storage account 


a) Storage services in Azure come under 4 primary categories, atleast in terms of storage account. 

1) Azure container:
-> Also called blob storage
-> Massively scalable object store for text and binary data 

-> great way to be able to access things via http, https or via standard Rest APIs available for your storage account. 
-> really good option: if we are looking for web hosting or just general storage where dont need to be accessing directly 

BLOBS: 
-> Images, documents, video, audio, big data, backup file, databases, logs 

2) Azure tables: Ideal for storing structured non relational keypair data 
-> Ideal for key/value data 

ENTITIES:
name=...
email=...
photoid=...
date=...

3) Azure queues: Messaging store for reliable messaging between application components 

-> Analogy to forum with series of threads 
-> It is a place to store messages where different types of application can talk to one another asynchronously . it is like producer/consumer where one job will produce image and another job will consume the image 
-> Designed for applications that need to co-ordinate with one another. 
-> Hence designed to be lightweight and quick. 

MESSAGES:
imagesToDownload 
imagesToResize 

4) Azure files: Managed files sharers for cloud or on-premises deployments 
-> Though binary large objects are stored in Azure containers we dont access it like a network share. 
-> But in Azure files we access it like a network file share 
-> Azure files is like a replacement for traditional network file share 
-> It is like accessing a drive in our computer 

---> useful for lifting and sharing traditional network shares into cloud , using them as storage location for user profiles for virtual desktop infrastructure, 

-> Hence a Great option for traditional file directory structures 

DIRECTORIES:
.txt,.exe,*.* 


DETERMINE STORAGE ACCOUNT KINDS 
b) We also need to consider what type of storage, we need in terms of backend performance.
-> All storage accounts are going to be encrypted at  a baseline   
-> They are encrypted using Storage Service encryption(SSE) for data at rest 

-> Storage account type is based on purely how fast the storage needs to be. 

b.1) 
Storage Account:Standard general-purpose V2
Recommended Usage: Most scenarios including blob, file, queue, table and data lake storage

-> This is available natively and there is nothing needs to be done to make it up and running 


-> for specialty scenario, we have speciality storage accounts like below 

b.2) 
Storage Account:Premium block blobs
Recommended Usage: Block blob scenarios with high transaction rates scenarios that use smaller objects or require consistently low storage latency 

-> Used for fast transaction rates and for extremely low latency 

b.3) 
Storage Account:Premium file shares 
Recommended Usage: Enterprise or high-performance file share applications 


-> Useful for high performance, high transaction rate, low latency  
-> for specific scenarios where you require use of paging blob infrastructure .. But this is focused on Azure Files 
-> Virtual hard drives that are being stored in a storage account for ultra specialized scenarios. 
-> Used rarely.  

b.4) 
Storage Account:Premium page blobs 
Recommended Usage: Premium high performance page blob scenarios 


-> For specific scenarios where you require the use of paging blob infrastructure 
-> Virtual hard drives that are being stored in a storage account for ultra specialized scenarios 
-> THis account type is used rarely on compared to others. 


c) DETERMINE REPLICATION STRATEGIES: 

-> Many different options are available for replication 


c.1)Single region:LRS: Locally redundant storage 
-> Baseline type of storage account we have
-> Lowest Level of redundancy we support
-> It is 3 copies of data in a single region
-> Azure takes your data in, at a single endpoint and then it replicates it immediately into 3 copies 
-> This ensures that if one disc dies, the other 2 are still running.  

-> Protects against disk, node, rack failures
-> Write is acknowledged when all replicas are committed. 
-> Superior to dual-parity RAID 

c.2) Single region:ZRS: Zone Redundant Storage:
-> Some Azure zone support availability zones 
-> In ZRS, we have three separate availability zones 
-> Each Zone has separate power, water, cooling i.e fully separate and isolated infrastructure
-> Thus if one of the major components of data center ever fails and would take out an entire region, instead only a zone goes down.  
-> Hence our data has higher level of redundancy by nature of it have more physical separation 
-> hence here also, write once, triple copy is done automatically

c.3) Multiple Regions : GRS - Globally Redundant storage
-> if you need to move beyond single region of replication and if we need some distance between our copies, THen we need to look at GRS 
-> Globally Redundant storage

-> Within Azure regions always have a pair 
-> Hence what we end up doing GRS, it will have 6 replicas of your data. 

--> One LRS cyp, 3 copies in your primary region, eg: Aus east 
	Secondary LRS copy in second region  eg: Aus west 
	
-> Thus we prevent against major disasters at regional level 

c.4) Multiple regions: RA-GRS : Read Access Global Redundant Storage 

-> We write always to the primary,eg: Aus east 
   We synchronize our data to Aus, south east.

-> We get a readable endpoint at our secondary region and make that replica work for us. 
-> IF you have two copies of application and you want to be able to read   static data from closer space to where your virtual machines are located,  
-> Then we have solution here:

-> We have all of the same features that GRS supports , but also that ability to read from secondary replica, 


c.5) GZRS and RA-GZRS 
-> They have same principles like read access globally redundant storage, but your first region is in an availability zone region 
-> Hence you get the same six replicas, but you have availability zones in your primary  
-> Hence we have even higher levels of resiliency whilst still taking advantage of features of Globally redundant storage  

-> Hence highest level of redundancy that azure offers 
is GZRS  and RA-GZRS 

c.6) Each rep, lica of data you have is something that we store , hence LRS vs GRS does have separate cost structures

-> Hence good to go to Azure price calculator to get the estimate of amount of data you want to store 

d) Access Storage: 
-> Until now we saw everything about storage account, now lets see about using the storage account 

d.1) How do we start accessing data itself: 
->  It depends on the type of data, you need to access 
-> Each storage service in azure: container, table, queue, file uses a separate end point like below 
-> Once we access these endpoint, then we are able to go to standard rest APIs or interfacing via network share or whatever it is able to pull data from it. 


-----
Every Object has Unique URL address - based on account name and storage type 

Container Service: https://mystorageaccount.blob.core.windows.net

Table Service: https://mystorageaccount.table.core.windows.net

Queue Service: https://mystorageaccount.queue.core.windows.net

File  Service: https://mystorageaccount.file.core.windows.net


------


d.2) It is possible to add custom domain names to your storage accounts and this can be done via DNS infrastructure

----------

-> If you prefer to configure a custom domain name 

CNAME record: blobs.contoso.com 

Target: contosoblobs.blob.core.windows.net 

----------------


e) Secure Storage Endpoints:
-> This is about securing of storage accounts 
e.1) By Default a storage account is publicly addressable, but that does not mean anyone can download the data. 

eg: for blob storage, default security posture is private 
-> This means someone needs to provide correct authentication and authorization to access data in your storage account itself. 

e.2) By default someone with correct authentication and authorization , could access your storage account from anywhere 
-> For your security posture, if you wish to ensure that your storage account can only be accessed by certain virtual networks in Azure or may IP addresses that reflect your organization, THen we need to select option "Enabled from all networks" under Firewalls and Virtual networks 

-> This will ensure that, only people who are coming from these networks or have your organizational ip addresses as their source ip can access the storage account. 

e.3) Then they can provide their authentication/authorization on top of that, to get the data they need. 
-> Hence it is adding a layer of isolation on top of your broad environment. 

e.4) 
..
Firewalls and Virtual networks restrict access to the storage account from specific subnets on virtual networks or public IPs 

Subnets and Virtual networks must exist in the same azure region or region pair as the storage account. 

....


f) Demonstration - Configure a storage account :
Create a storage account
Configure storage account settings 

f.1) Go to azure dashboard -> Search "Storage Account"--> Create -> 

BASIC: 

Project details:
Subscription/Resource group 

Instance details :
Storage account name/region/
Unique storage location name -> which needs to be globally unique amongst all storage accounts.  and it should be DNS compatible 
Performance: Standard or Premium 
Redundancy: Geo-redundant storage(GRS) 

ADVANCED
Blob storage: Allow cross-tenant replication/Access tier 
Azure Files: Enable Large file shares 

Networking: 
Network access: 
Network routing: 

-> Review and Deploy 



g) Recap:
-> Storage accounts are the primary way we store data in Azure 
-> Many different types of storage APIs, depending on your specific requirements like Data replication to different regions or single one etc 
 
https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-17


18) AZ-104 Configure Blob Storage (18 of 31)

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-18

Administer Azure Storage: Configure Blob storage 

-> IN this lesson we will be looking on Administer Azure storage - More specifically - blob storage 
-> Blob or Binary large Object 



Learning Objectives - Blob storage:
Implement blob storage 
Create blob containers 
Create Blob access tiers 
Add blob lifecycle management rules 
Determine blob object replication 
Demonstration - Configure blob storage 
Learning recap 



a) Blob or binary large object is a really versatile and flexible storage mechanism in Azure 
-> We can use blob for a range of different things. 
-> Because of its easy accessible mechanisms via the web - we can use it for Applications, general storage, archiving and whole range of things 

b) Implement blob storage 
-> Blob storage is any unstructured data in cloud.
-> blob storage helps store unstructured data in the cloud 

b.1) Structured data is something we see in database or excel sheet.
-> WHile in blob, we are focussed here on general unstructured data: text or binary data of any kind. 

-> there are many different uses of this 

1) Produce disclosure statements for an insurance company 
2) Government agency that needs to put out information to the public 
-> if you need to pass some information to someone, we can easily pass it to them using a storage account. 

b.2) Common Uses:
-> Serving images or documents directly to a browser 
-> Storing files for distributed access. 
-> Streaming video and audio 
-> Storing data for backup and restore. disaster recovery/archiving 
-> Storing data for analysis by an on-premises for azure-hosted service 


b.3) General structure of a storage account with blob data located within it: 

Storage account(Production)----> Containers(Pictures/Movies)---> Blob(.jpg/.avi) 

-> Each of these containers is like a classification for the type of data that is going to be stored within 


b.4) As part of structure, under the containers we have blobs : files that you need to store 
-> We use containers within container storage to be able to just divide and ensure that blobs can be accessed in a clean manner and you know where things are 


c) Creating blob containers :
-> All blobs must be in a container 
-> Accounts have unlimited containers 
-> Containers can have unlimited blobs 

c.1)  Containers can be created with a few different types of access level. 
--> This is the thing that defines whether someone should be able to access it publicly or if you need to provide authentication and authorization to read the data located in that container. 
-> This is because all blobs must be in a container, we can easily customize this for different types of public access level depending on what you are storing  
-> Restrict access using public access level 


c.2) Create Blob access tiers :
Hot tier - Data that is accessed or modified frequently 

Cool tier - Data that is frequently accessed or modified and stored for at least 30 days 

Cold tier - data that is infrequently accessed or modified and stored for atleast 90 days 

Archive - Data that can tolerate several hours of retrieval latency and will remain in archive tier for atleast 180 days 
-> No quick like cool or cold. 
-> Multihour retrieval process  
-> lowest cost per gb for storing your data long term 

d) Add Blob lifecycle management rules:
-> How do we move blobs between each of these tiers of data 

-> This can be done by setting a lifecycle management rule 
....
Life Cycle management is transitioning of blobs to a cooler storage tier to optimize for performance and cost 

delete blobs at the end of their lifecyle 

Apply rules to filtered paths in the storage account 
....


d.1) Lifecyle management is more than just moving from hot to cool to cold ot archive

d.2) It is also deciding when a blob has reached the end of its life cycle in the organization  

d.3) Rules to filtered paths in storage account: 
-> Hence depending on your specific requirements, you can have a lifecycle management rule that does: hey after 30 days move data to cool 
-> once something hits 90 days of no access,move it to cold.  
-> once something hits 180 days, move it to archive. 
-> once you hit your 7 year retention period for that data, we can have it automatically be deleted at the end  

-> it is super simple way to move between tiers without having to manually proceeding and filtering your processes. 


d.4) This helps to achieve best possible savings in your environment. 


e) Determine blob object replication:
-> blob storage has ability to replicate arbitrarily to any region 
-> The way we do this is on a per container basis. 


....
Asynchronous to any other region 
Minimizes latency for read requests 
Increases efficiency for compute workloads 
Optimizes data distribution 
Optimizes costs 
....

e.1) in this example, we have primary region in Region1 
-> Let Region1 be Australia east. Next we need to choose where it makes sense to replicate specific parts of data to other locations. 
-> The paired region for Australia East is Australia South East, But region2 could be in UK and region 3 in singapore.  
-> It is totally our call, on how we want to replicate the data as far as regions are concerned. 

Region1:Source Account{SourceContainer1:blob1.txt/blob2.txt}---Asynchronous Replication----> Region2:Source Account{SourceContainer1:blob1.txt/blob2.txt}

Region1:Source Account{SourceContainer1:blob3.txt/blob4.txt}---Asynchronous Replication----> Region3:Source Account{SourceContainer1:blob3.txt/blob4.txt}




f) Demonstration - Configure Blob Storage 
-> Create and Configure a container 
-> Manage blobs in the container

f.1) In azure portal go to the storage account already created.  
-> In the storage account page, choose containers 
-> Container storage is where blobs live 

g) Recap:
-> Blob storage is a way to store arbitrary random fiels that you need to keep of any type in the cloud. 
-> It can be logs, images, pdfs
-> Blob storage gives more flexible way to keep your data, no matter how quickly or often you need to access it. 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-18 end 


19) AZ-104 Configure Storage Security (19 of 31)

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-19

Learning Objectives:
Review Storage security strategies 
Create shared access signatures 
Identify URI and SAS parameters 
Demonstration - Configure storage security 
Determine storage service encryption 
Create Custom managed keys 
Apply Storage security best practices 


a) Review Storage security strategies

a.1) Storage Service Encryption :
-> At a baseline, Azure storage service that we use which underlies all other azure services already has baseline encryption 
-> We encrypt in our environment to ensure that there is level of protection even at that baseline level. 
-> Beyond this, there are many different types of additional encryption and additional security that we can add as layers on top of this baseline 

a.2) Authentication with Entra ID and RBAC 
-> If we choose we can add authentication to files in azure using Entra ID and role based access control to ensure only people who specifically have access, can acess the storage account. 

a.3) Client side Encryption, HTTPs, and SMB3.0 for data in transit: 
-> We also support client side encryption and https for any type of general file access within blob 
-> If we make use of Azure files, we also support SMB3.0 to ensure highest level of standard of encryption for those network shares.  

a.4) Azure disk encryption 
-> Indeed Encryption at rest goes beyond the physical hard drives. 
-> Azure disks which we use for Virtual machines also have additional encryption 
-> Thus we are double encrypting as we go through. 
-> We have control over, how this is encrypted - using microsoft keys or your own key 

a.5) Shared Access Signatures - delegated access 
-> Shared access signatures, is a great way to give individuals with access to a single blob in a storage account or may be a container within a storage account. 
-> This gives us the ability to have timeboxed, delegated, clear access generated on the fly  
-> Even if we are not able to use Entra ID, we still have ability to scope what people can access and how they are accessing it for your storage account. 


-> The last below 2 are some broader security strategies which are openness in a way. 

a.6) Shared Key - Encrypted signature 
-> Shared key is a way to access all data within a storage account 
-> This is utilized for 3rd party applications that need to reach out to the cloud and be able to write frequently to that storage account directly  

a.7) Anonymous access to containers and blobs: 
-> We also have ability to anonymize access to containers and blobs 
-> So if you have things that need to be publicly accessible - you have the ability to set that up. 

b) Create Shared Access Signatures :

...
-> Provides delegated access to resources 
-> Grants access to clients without sharing your storage account keys 
-> The account SAS delegates access to resources in one or more of the storage service. 
-> The service SAS delegates access to a resources in just one of the storage services 
...


b.1) Without going to setting up Entra ID and permissions, this is the cleanest and simplest way to ensure that you are able to provide access to those single files in a blob storage or storage account with blob storage in it, within time boxed period for specific IPs or a specific set of clients.  

Usage: 
-> if it is on off like sending logs to a third party for analysis , then this is a perfect way to use the SAS shared access signature key 
---> We can do a lot with SAS to ensure that only right people are reading this data. 

b.2) Create Shared Access Signatures 

...
Provides delegated access to resources 
Grants access to clients without sharing your storage account keys 
Account SAS delegates access to resources in one or more of the storage services. 
The service SAS delegates access to resource in just one of the storage services. 
...

-> if there is a know list of IPs to whom we need to send, we can utilize filter to ensure that only those IP addresses go through  
-> Shared access signature ensures that only right people are reading this data. 

-> When we break down a SAS token and all of the components in it, 

b.3) Identify URI and SAS parameters 


...
A SAS is a signed URI that points to one or more storage resources 
Consists of a storage resource URI and SAS token 
Includes parameters for resources URI, storage services version, resource types, start time, expiry , resource, permissions, IP range, protocol, signature 
...


-> spr=https means it tells that we require secure transfer via https to be able to access this data. 
-> The signature at the end is the auto generated key 
that gives this person access 
-> These tokens are what we will be generating if we need to some one , this time boxed specific access. 
eg: sign=ddhwehfweuuee

c) Demonstration - Configure Storage security 
-> Generate a shared access signature 
-> Review the configuration permissions 
-> Use the SAS URL to test the permissions.

-> If we go to a resource in Storage account, in that page we can see generate SAS token and using that, we will be able to generate the token and will be able see BLOB SAS token and BLOB SAS URL in same page

-> If we are doing command line or do programmatic access, BLOB SAS token is useful 


d) Determine Storage Service encryption : 

..
-> Protects your data for security and compliance 
-> Automatically encrypts and decryps your data 
-> Encrypted though 256-bit AES encrption 
-> Is enabled for all new and existing storage accounts and cannot be disabled 
-> Transparent to users 
...

-> Next we will talk about Baseline encryption that we have in storage account. 

d.1) For both blob storage and file storage we are able to pick and choose how we are encrypting our files at rest. 

d.2) Storage service itself comes with two options for encryption: 

1) MICROSOFT MANAGED KEYS: Keys that are generated by microsoft and stored by Microsoft against your storage account with AES 256 bit encryption 
-> This is the default posture that we pick to ensure that all storage is encrypted no matter what 
-> But we do have option for Custom Manged keys 
2) CUSTOMER MANAGED KEYS: CMKS are an alternative, where you use your own method to generate storage encryption key of the correct standard and provide it to us. 
-> If you do this, we can effectively put on your storage account, a secondary lock with a guarantee that Microsoft does not have access to that key 
-> You will store the key in a key vault, once you have externally generated it. 
-> you mark the storage account for customer managed keys and now we are encrypting use the key that you have provided. 

-> In CMKs, if key is lost, there is no way to help because it is a customer managed key 
-> Hence CMKs provide the best possible flexibility, if you are in a high compliance environment

e) Applying Storage Security best practices 

...
1) Always use https to create or distribute a SAS 
2) Reference stored access policies where possible. 
3) Use near term expiration times on an adhoc SAS 
4) Use Storage analytics to monitor your application 
5) Be careful with SAS start time 
6) Be Specific with resource to be accessed. 
7) Understand that your account will be billed for any usage 
8) Validate data written using SAS 
9) Dont assume SAS is always the correct choice 

....

e.1) Always use https to create or distribute a SAS 
-> We have called out SAS here because in SAS there is an option to use https or http 
e.2) Reference stored access policies where possible:

Look to stored access policies as a way to manage permissions when we are going to be generating SAS tokens  
->Stored Access policies allow us to define a set of permissions that we wish to reflect for users 
-> Hence there is something you are doing commonly over and over again , rather than ticking boxes each time 

e.3) Use near term expiration times on an adhoc SAS 

Extremely important to timebox your sas tokens to what is actually required: 
-> Should not set tokens with a multiple month expiry, if all that is needed is an hour 

e.4) Be careful with SAS start time 
-> With ability to set different time zones, it is important to make sure that people only have access to the token from WHEN they should have access and not earlier 

e.5)  Use Storage analytics to monitor your application 
-> There are deep analytics available within storage accounts 
-> Hence make use of analytics and auditing engines to ensure that people are doing, what they said they would be doing 

e.6) Be Specific with resource to be accessed. 
-> Should be specific with the resources that you allow them to access. 
-> It makes monitoring and auditing significantly easier if we scope things down only to the exact required pieces 


e.7) Dont assume SAS is always the correct choice 
-> We have ability to use User Accounts which may be a bettwe solution for us. 


e.8) Validate data written using SAS 
-> Always validate any data written by an SAS token 
-> THis is because anyone with access to the token has access to the storage endpoint 
-> Hence we need to double check if it is legitimate. 

---> Zero trust principles, say verify all along the way. 

e.9) Understand that your account will be billed for any usage
-> Undersand that providing a token that has right access means people can write to your storage account - which means that you will be billed for any usage. 
-> Hence we need to trust the people on other end to be responsible with token we provide to them 


f) Recap: 
-> No of different ways of securing storage account from the perspective of encryption, access 
-> Looked at SAS(Shared access signatures) as a great way to give individual access to files and blobs in an environment  
 
 https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-19 end 
 


20) AZ-104 Configure Azure Files and File Sync (20 of 31)

Learn how to configure Azure Files and Azure File Sync.

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-20

-> In this lesson we will look on Administering Azure storage with a particular focus on one area of our storage platform which is Azure files.  


-> Azure files are a great way to be able to access data through traditional network file share formats 
-> Hence we need to do a comparison from files to blobs 
-> These are the two main ways we store data in a storage account. 

Learning Objectives:
Compare files to Blobs 
Manage File shares 
Create File share Snapshots 
Demonstration - Configure file shares 
Configure storage with tools 

-> As part of this module, we will not cover Azure File sync 

a) Compare Files to Blobs 

a.1) Azure Blobs 
-> Client libraries and Rest interface that allows unstructured data(flat namespace) to be stored and accessed at a  massive scale in block blobs 

1) Azure blobs or binary large objects are utilized for general storage for unstructured data and are extremely useful where we need to access things via Http or Https methods via web browser or Rest API


WHEN TO USE: 
-> Support streaming and random access scenarios 
-> Access application data from anywhere 


a.2) Azure Files:
-> SMB interface, client libraries and Rest interface that allows access from anywhere to stored files 

1) Azure files while they do have a rest API interface is mostly access via a SAMBA share , which is our network file share 

This is like logging to a computer and accessing a file in a drive 
 
 
 WHEN TO USE: 
a.2.1) File shares as they reflect as standard network share are extremely useful for a lift and shift setup
-> Lift and shift : we take an application in its current state and move it to the cloud  

-> Because this looks like a normal share to general applications, it works fantastically for apps posted on virtual machines 

a.2.2.) Store shared data across multiple virtual machines 

a.2.3) If you wish to store your data in a way that a legacy application will understand  , Azure files should be the choice , but it has many modern users as well. 

a.2.4) Store development and debugging tools that need to be accessed from many virtual machines. 


b) Manage File shares:
-> File shares have a number of pieces of configuration , we need to keep in mind 
-> one of the most interesting ones is Authentication 

b.1) Via File shares we support the ability to authenticate with an additive directory domain services domain - a traditional on prem domain 

Authentication Method : Active Directory/Storage account key 

-> Active directory is traditional on prem domain 

b.2) Whether to use AD or Storage account key  : we will be able to effectively mount these file shares directly to your PC 

b.3) Azure files shares: also supports linux and MACoS mounting on these file shares 

b.4) We also support Secure transfer required which is part of the SMB 3.0 protocol 

b.5) File share quotas

-> File shares are useful in many different scenarios , But one of the best thing what file shares could do is: Creation of snapshots 


c) Create File share snapshots 
-> Snapshots are designed for quick instantaneous files share level restoration  
-> Effectively we have our file share tracking along we captured at a point in time, which can be restored instantaneously 

....
-> Incremental snapshot that captures the share state at a point in time 
-> Is read-only copy of your data 
-> Snapshot at the file share level and restore at the file level. 
-> Protection against application error and data corruption 
-> Protection against accidental deletions or unintended changes 
-> General backup purposes. 
....

c.1) Useful when you want to test a new application or concerned about accidental deletion of files 

c.2) Can be useful for short term backup purposes
c.3) Restoration process can be done entirely via the portal 
-> no need for mounting of virtual drives 


d) Demonstration Azure file share Snapshots 
-> Go to storage account, in blade on left select file shares 

Data Storage -> File Shares 

---> By default we have few pieces of information straight away 

d.1) First is : Do support active directory sign in ? 
-> This is not configured by default, but the ability to sign in with active directory domain services is supported for Azure file shares 
d.2) We have some default permission structures that we can set 
d.3) Ability to setup soft delete 
-> Soft delete is like a recycle bin for individual files where we can undelete files within 7 days was we have configured here. 
d.4) Here he can see the maximum capacity is 5 TB and security is set for maximum compatibility 
-> There are ways to make it more restrictive depending on your scenario and your specific requirements 

d.5) Demonstration: Creation of File share 
New File share:
1)Basics:
File Share Name /Tier 
-> In addition to supporting hot and cool tier we also support Transaction optimized and premium 
-> Transaction optimized is defualt because it provides a great balance between the writing of file and reading of files for general file shares.   
-> But there are other alternatives within hot and cool, if we wish to use them instead. 

Performance: 
-> We can evaluate quickly, what the performance will be, by selecting different tiers by looking at the performance tab which lists the following based on selected data:
Maximum IO/s/ Maximum capacity/ Large file shares 

2) Backup 
Enable Backup/Recovery Services vault/Vault name-> Resource group/Backup policy

3) Review + Create  

4) After creation, we can see many details about the file share:
Share URL : Location where it is there 
Redundancy: Where its replica is located 

Connect Tab -> We can see command line which you need to run to ensure that you are able to make changes and access this file share more broadly:  for Window, linux , Macos 


Upload : Helps to upload files directly


e) Demonstration of Snapshots 
In Portal -> File Share -> Operations : Snapshots/Backup 
e.1) Snapshots -> Add Snapshot 
-> Snapshots are designed to be extremely fast to be created and extremely easy to restore from. 
e.4) if we wish to restore we can go to snapshot/restore page and manually restore the file



TOOLS THAT HELP TO MANAGE AND USE FILE SHARE
f) Use Storage Explorer: 
-> This is a program we can install on your machine which allows you to access Blob, Queue, Table and File storage directly from your machine.  
-> Depending on whether you have active directory setup or Entra ID setup or SAS tokens, we can easily access our files straight from this one location  

...
STORAGE EXPLORER:
-> Access multiple accounts and subscriptions 
-> Create, Delete, view, edit storage resources 
-> View and edit Blob, Queue, Table, File, Cosmos DB storage and Data lake Storage 
-> Obtain shared access signature(SAS) keys 
-> Available for Windows, Mac and Linux 
...


g) Command line interface : AzCOpy 
-> As an alternative, azure also supports command line interfaces 
AzCopy is the simplest way to upload and download individual files into our environment 

g.1) AzCopy is a command line utility designed for copying data to and from Azure blob, file and Table storage 
g.2) Available on Windows, Linux and MacOs 
g.3) Designed for copying data to and from Azure blob, file and table storage 
g.4) Authentication options include Microsoft Entra ID or SAS token 

eg:
 azcopy copy [source] [destination] [flags] 
 
 
h) Use the import and export service: 
-> Import/export service is a way to bulk ingest and bulk export data from the cloud using physical disks 
-> IMPORT JOBS move large amounts of data to Azure blob storage or files 

Your tasks(Prepare Disks/Create Job)ship---> Azure datacenter tasks(Receive disks/Transfer data/Package disks)ship----> Your Tasks( Receive disks/View data in Azure storage) 

Sample classic story:
Cheverolet travelling down highway  has way higher bandwidth than any network connection i can think of 


h.1) In import jobs: we prepare disks, encrypt them, load the files that you need to put in your storage account and physically send them to our datacenters 
h.2) Technicians then upload them, ready for you to decrypt and make use of 
h.3) This is genuinely faster than a network store. 

h.4) Export jobs are in the other direction 
-> We can take data in cloud, send us a disk, we load it on to the disk, encrypt it and send it back to u.
-> We can unlock that disk and you will have access to things in cloud directly 

Export jobs move large amounts of data from Azure blob storage(no files) 


Your Tasks(CreateJob)ship--->AzureDatacenter tasks(Receive disks/Transfer data/Package disks)ship----> Your tasks(Receive and unlock disks) 

h.5) Import / Export though niche, it is extremely useful for initial migrations and seeding for file shares when you are initially getting thins ready 

i) Recap :
-> Azure files are great way to extend traditional file share infrastructure into the cloud 
-> Whether you are looking to lift and shift an application or sending something up for  user profiles with general virtual machines or with virtual desktops - it offers a simple for you to just  use the traditional network file share.
-> Saw couple of ways to import and export data 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-20 end 


21) AZ-104 Configure Virtual Machines (21 of 31) 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-21


Learn how to configure virtual machines including sizing, storage, and connections.

Learning Objectives - Configure Virtual machines 
Review Cloud Services Responsibilities 
Plan virtual machines 
Determine virtual machine sizing 
Determine virtual machine storage 
Demonstration - Creating VM in portal 
Connect to Virtual Machines 
Connect to Windows Virtual machines 
Connect to linux virtual machines 


a) Review Cloud Services Responsibilities Model: 
-> This is a model, we use to reflect who is responsible for what amongst Microsoft and yourselves(the customers)
-> When you choose to deploy something in azure - how much do we need to take care of? 
-> Majority of services that we use in Microsoft will exist in PaaS or SaaS space 
PaaS: Platform as a service 
SaaS: Software as a service 

a.1) Azure SQL database, Office365, Outlook etc is a Software as a Service 
a.2) A virtual machine sits firmly within infrastructure as a service 
a.3) A VM gives you very low levels of control :
 Install OS, Choose how network is defined , install different applications and fully control identity and directory infrastructure for those virtual machines 
a.4) When using VMs there is lot of responsibility on the customer. 

..........................................................................

A) On Prem Always owned by Customer 

B) Responsibility always returned by customer:
1) Responsibility: Information and data 
SaaS: Customer 
PaaS: Customer 
IaaS: Customer 

2) Responsibility: Devices(Mobile and PCs) 
SaaS: Customer 
PaaS: Customer 
IaaS: Customer 

3) Responsibility: Accounts and identities 
SaaS: Customer 
PaaS: Customer 
IaaS: Customer 


C) Responsibility varies by type: 
1) Responsibility: Identity and Directory infrastructure
SaaS: Shared 
PaaS: Shared 
IaaS: Customer 

2) Responsibility: Applications 
SaaS: Microsoft  
PaaS: Shared 
IaaS: Customer 

3) Responsibility: Network Controls
SaaS: Microsoft  
PaaS: Shared 
IaaS: Customer  

4) Responsibility: Operating System 
SaaS: Microsoft  
PaaS: Microsoft 
IaaS: Customer 

D) Responsibility transfers to cloud provider
1) Responsibility: Physical hosts 
SaaS: Microsoft  
PaaS: Microsoft 
IaaS: Microsoft 

2) Responsibility: Physical Network  
SaaS: Microsoft  
PaaS: Microsoft 
IaaS: Microsoft 


3) Responsibility: Physical Datacenter  
SaaS: Microsoft  
PaaS: Microsoft 
IaaS: Microsoft 


..........................................................................



b) Plan Virtual Machines: Initial setup of virtual machine  
b.1) Planning begins with Network 
-> A virtual machine requires a virtual network to function 
-> We need a private space to deploy virtual machine's network interface card. 
-> We need to ensure that we have VNET to land your virtual machine in 
b.2) Valid Name for Virtual machine 
b.3) Choose a Location 
-> Each region has different hardware and service capabilities 
-> Locate virtual machines as closely as possible to your users and to ensure compliance and legal obligations 
b.4) Consider Pricing --> Hour basis or reserved instance format 

b.5) Determine Virtual machine sizing 

-> General purpose: Balnced CPU to memory ratio
---> Normal VM without specific requirements. They offer good CPU-to-memory ratio for general usage. 
-> Compute optimized - High CPU to memory ratio
-> Memory Optimized - High memory-to-cpu ratio 
-> Storage Optimized - High disk throughput and I/O
-> GPU  : Specialized virtual machines targeted for heavy graphic rendering and video editing 
-> High performance compute - Our fastest and most powerful CPU virtual machines. 

b.6) Determine virtual machine storage 


Each Azure VM has two or more disks 
-> At a baseline virtual machine will have two disks available to it. 
● OS disk 
● Temporary disk(not all SKUs have one, content can be lost)
● Data disks(optional) 

OS and data disks reside in Azure Storage acouns 
● Azure-based storage service 
● Standard(HDD, SSD) or Premium (SSD), or Ultra(SSD)  

Azure VM's use managed disks 
-> These are resources in azure that sit alongside a virtual machine 


As we create the VM, disk also gets created at the same time. 


c) Demonstration - Creating a VM in portal 
-> Create a virtual machine 
-> Connect to the virtual machine - Bastion, RDP, or ssh 

c.1) Goto Dashboard -> Search bar"Virtual machine"-> Create 
c.2) There are 3 options to create virtual Machine 

1) Azure Virtual machine 
		-> Fully customized virtual machine 
		-> Use this when you know completely what you want 
2) Azure virtual machine with preset configuration
-> We will be able to choose recommended defaults that match your workload 
i) Select Workload environment : Dev/Test or Production default 
ii) Select a workload type: General purpose(D-Series) default 
							Memory optimized(E-Series) 
							Compute Optimized(F-Series) 
iii) When we continue to create VM it will prepopulate many of the choices that we should make along each of these tabs 
Basic Details: 
Subscription details 
Instance details: 
VM name/Region/ Availability Zone /Image
-> Here dev will have single availability zone while prod will have multiple availability zones.
Security Type: Standard/Trusted launch virtual machines  
Image-> Ability to use market place images or it is also possible to bring your own image 
Size  
eg: Standard_D4s_v3 - 4 vcpus, 16 GiB memory($316.82/month) 


iv) Administrator Account: username/password 

v) Inbound Port rules: 
-> Here we choose what port we wish to have open 

-> We pick not to open RDP ports in "Select inbound ports" 

-> There are two sections: Public inbound ports and Select inbound ports 

vi) Licensing 
vii) Disks for Virtual machine : Os disk/Size| type| Key manangement | Delete with VM 
-> Create and attach a new disk option or attach an existing disk 
viii) Networking -> Network Interface | Virtual network |Subnet |Public IP 

-> Networking is the tab where we specify where we want our virtual netwok is going to live. 
-> We specify the vnet we want in Virtual network 
-> We need pick a Virtual network/Subnet etc 
-> We also need to specify if our virtual machine requires a public ip or not. public Ips are utilized when someone needs to access something on virtual machine from the public internet 
-> Option for: Delete NIC when VM is deleted 



ix) Load Balancing 
-> Load Balancing options | Azure Load balancer | Application gateway 
ix) Monitoring tab 


x) Monitoring : 
-> Boot diagnostics : it will create a storage account that exists alongside this virtual machine to store any broad logs that it collects

-> Alerts / Diagnostics  

xi) Review + Create 
-> In Review+ Create page it shows the cost estimate 


d) Once we create the VM, we need to connect to it. 

-> for that we have the connect button 
d.1) Clicking connect button takes us to a page that gives you details about the virtual machine 

d.2) First it will tell how we we connect to it. 
-> In our case it says: Connect using private IP address | 10.0.1.4 

d.2) It also shows what port we are expecting to remote into this virtual machine 
-> For windows default port for rdp is 3389 
-> Hence it shows as: Port 3389

d.3) Other ways to connect this virtual machine are by using tab: More ways to connect 

d.3.1) Go to Bastion basic or standard 
-> Bastion is a way for us to connect via the web browser and directly access this virtual machine without having to open up a public ip 

d.3.2) Windows Admin Center 
-> Ability to use a GUI based tool for accessing this environment 
d.3.3)  Windows administrative service 

d.3.4) Native SSH:
-> if it is a linux based machine , we can also use SSH 

d.3.5) Serial Console :
-> if all ways to connect to virtual machine fails,  last way is to use serial console access 

e) Configuring Bastion 
Create Bastion 

-> We have automatic "Deploy bastion" or "Configure manually" button 

f) so far we saw how to connect to the vm via different ways, now we will look into architectures of these options of connecting 

g) Architecture of Azure Bastion 
-> Azure bastion is a service that allows you to remote into a virtual machine directly through a web browser 
-> As a user, you login to the azure portal , we follow the authentication process 
g.1)  We use TLS across 443 https traffic , in order to connecto the azure bastion service 
g.2) Bastion is deployed directly into your virtual network and bastion will have network security groups(nsg) will be used to filter traffic 
-> By this it is ensured that we connect only to virtual machines which have access via bastion 
-> if you have remote desktop environment with 20 or so users or some administrators whos need to work in your environment - this offers a great way to connect into those VMs, without having to open these virtual machines to public IPs or open ports more broadly 


User(1)---> TLS---> Azure portal(2)---443/Internet---> AzureBastionSubnet(3)-----> Private IP /3389/22 RDP,ssh----> Target Azure VM----> AzureBastionSubnet(3.1)-->4----> Linux/Windows---> User(1.1) 


g.3) hence bastion is really a very useful way to facilitate connectivity and remote desktop connections without having to open things up broadly 
-> Bastion can be used as a security measure and for general eas of use 

h) Other two options we say are: 1) RDP connection - standard remote desktop protocol 
-> This creates a GUI session and access inbound traffic on tcp port 3389 
2) WinRM - creates a command line session so that we can run scripts 

i) Even linux offers in the same way : 
-> ssh connection 

j) Even if bastion is not suitable to use, there is always a mechanism for connecting and getting access to virtual machines 


k) Recap:
-> Introduction to Azure virtual machines(Sandbox) 
-> Different storages available 
-> Some of those pre-requisites we need to have in place 
-> Choose the right disk storage for your virtual machine 
-> Create a virtual machine in Azure(Sandbox) 
-> Create windows virtual machine in Azure(Sandbox) 
-> different ways of connecting into azure virtual machine 
-> Connect to virtual machines through azure portal by using Azure bastion 

-> Sandbox indicates an additional hands on exercise 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-21  end 


22) AZ-104 Configure VM Availability (22 of 31)

-> Learn how to configure virtual machine availability including vertical and horizontal scaling.


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-22

->  In this lesson: on Administering virtual machines topic , we will be focussing on Virtual machine availability 
-> There are many different ways to deploy virtual machines to ensure higher level of availability 


Learning Objectives: Configure Azure virtual machine availability introduction 
-> Plan for Maintenance and downtime 
-> Setup availability sets 
-> Review update and fault domains 
-> Review availability zones 
-> Compare Vertical to Horizontal scaling 
-> Create scale sets(2 student topics) 
-> Configure Autoscale(2 student topics) 
-> Demonstration - Virtual machine scaling 
 
 
 a) Plan for Maintenance and Downtime: 
 a.1) Unplanned hardware maintenance 
 -> When the platform predicts a failure, it will issue an unplanned hardware maintenance event 
 -> eg : Catastophic disc failure or CPU suddenly crashing 
 
 Action: Live migration is done, to ensure that virtual machine is up and running 
 a.2) Unexpected Downtime 
 -> It is when a virtual machine fails unexpectedly 
 
 Action: Automatically migrate(heal) 
 -> We migrate virtual machine to a new hardware and ensure that heals automatically to bring things online  
 
 -> Also Azure notifies you for any unprecedented situation in hardware via Azure health systems 
 
 a.3) Planned Maintenance 
 -> events are periodic updates made to azure platform 

Action: No action needed  

######what is azure Sandbox########
Azure Sandbox is a collection of interdependent cloud computing configurations for implementing common Azure services on a single subscription.
#########

b) Setup availability sets 
-> To guarantee uptime, availability sets are great way to protect ourselves against these unscheduled downtime actions 
-> To setup availability setups we need to tell : where your virtual machines are deployed, tell no of fault domains required, tell no of update domains required 
	For now, just keep in mind that: more domains means more virtual machines 
	-> We will have higher costs, since there is more virtual machines running 
-> We need to combine virtual machine deployment with a load balancer in order to guarantee that traffic will be distributed amongst virtual machines in the availability set 
-> This also means that application needs support, spreading data across multiple virtual machines 
-> It is highly recommended to " choose to use managed disks" for these virtual machines in the availability sets as a way of guaranteeing that data is stored in an equally available format as the virtual machines 

c) Review Fault domains and Update domains 
-> 2 fault domains and 2 update domains 

...
Fault domains are a group of virtual machines that share a common set of hardware, switches,  that share a single point of failure.  VMs in an availability set are placed in atleast two fault domains 
Update domains: allows azure to perform incremental or rolling upgrades across a deployment. during planned maintenace, only one update domain is rebooted at a time 



c.1) Fault domain is a physical rack in datacenter with separate hardware, separate switches all of the things are in a rack stacked on top of one another. 
-> Within that rack we are going to run virtual machines where the disks, networking component etc live 
-> By selecting multiple fault domains, we will be deploying virtual machines, across different physical hardware racks in our data center  
-> By doing this, we are guaranteeing that if there is a hardware fault and we do need to take down a rack - Then your virtual machine and still the application running in it is going to run continuously

Fault domain1[Rack{Virtual Machine(UDO) | IIS1}]---Web availability Set--------Fault domain2[Rack{Virtual Machine(UDO) | IIS1}] 
Fault domain1[Rack{Virtual Machine(UDO) | SQL1}]---SQL availability Set--------Fault domain2[Rack{Virtual Machine(UDO) | SQL2}]

c.2) Other type of domain that we support is the update domain. We set this up on each tier of an application to ensure that, if there is an update required, that will require us to shutdown virtual machines temporarily  or migrate them to a different piece of hardware which could result in down time  , we only update one virtual machine at a time in your update domain. 
-> So NO matter what: virtual machines will remain up in your application  and your app does not go down. 

c.3) These offer different ways of increasing the availability of your system 
 -> By using and selecting multiple fault domains and multiple update domains, we can give an availability that  matches baseline in our environment 
 
 
c.4) More fault domains and more update domains means more virtual machines. Hence there is a higher cost associated with it . 


d) Review Availability Zones:
In certain regions we have availability zones as an additional factor that you can consider for general availability 
-> Big difference between standard regional deployment and an availability zone is the guarantee of separation 
-> Each availability zone is going to having separate power, separate cooling, separate networking and a separate physical location fromt he other availability zones. 

d.1) What this means, is that each of these zones is independent 
-> They will be close enought so that networking is going to be extremely low latency. But separate from one another. 
-> Thus even if catastrophic situation happens in one availability zone, other availability zones will continue to run. 
-> Thus by doing this, we can protect against a single data center failure, without having a multi region deployment.

d.2) Availability zones is effectively combining both the update domain and the fault domain principle.   
-> We can configure availability sets in regions that support these availability zones to increase your service level agreement to virtual machines. 

e) Compare Virtual to horizontal scaling 

..
Vertical scaling(Scale up and scale down) is the process of increasing or decreasing power to a single instance of a workload; usually manual. 
Horizontal scaling(scale out and scale in) is the process of increasing or decreasing the number of instances of a workload; frequently automated. 
...


-> Scaling is a slightly different tact for availability 

e.1) There are two broad types of scaling to ensure availability of an application, not so much from an unexpected downtime but simply from demand.  
e.2) Vertical scaling is the traditional resizing that we would do . 
-> Where a technician will shutdown a virtual machine, give more cpu cores, more RAM and spin it up again    
e.3) making one virtual machine bigger typically results in some downtime, as we need to do the power off while we do the resize. 
e.4) Hence modern applications choose horizontal scaling instead. 
-> you have large amount of compute power in cloud and use it when required.  
-> Idea is to setup a baseline. Lets say one virtual machine to run your application overnight. 
	But when hits 9:00 AM, we know there will be a spike in demand from users. 

e.5) Hence we will add an additional virtual machine . Then using a load balancer we can distribute traffic amongst those virtual machines and ensure that people who are accessing your website or application are going to have a performative experience   
e.6) As the ability to scale out can be set dynamically, we can continue to add more and more virtual machines upto to the maximum limits based on cost or technical standpoints  


f) Create Scale Sets 
-> Scale sets have a number of different ways to configure them. 
-> Technically we can configure them in a flexible or uniform format  by Setting Orchestration mode as flexible or uniform format. 

...
Orchestration:
A scale set has "scale set model" that defines attributes of virtual machine instances (size, number of data disks, etc). As the number of instances in scale set changes, new instances are added based on the scale set model. 
....


....Creating scale sets...
-> Instance count: Number of VMs in the scale set(0 to 1000) 
-> Instance Size: The size of each virtual machine in the scale set 
-> Azure Spot instance: Unused capacity at a discounted rate. 
-> Use Managed disks 
-> Enable scaling beyond 100 instances 
.................



f.1) If Orchestration mode is flexible, then we scale up and down, based on the requirements we see. 
     while uniform means , it will be uniform and optimized for large scale stateless workloads with identical resources 
f.2) When we create a scale set, all we need to know is :what is the  Size of virtual machine  that are going to use, what network we are going to deploy , what operating system that you are going to run 
-> if you are going to use a custom image, bring your own, otherwise select your own image from the market place images that are available. 
f.3) We may require small piece of orchestration to install any required applications 
f.4) Scaling is designed to work beyond 100 instances, hence we can go extremely flexible  
-> Lot of smaller virtual machines that scale up and down to meet that demand.  


g) Configure Autoscale 

...
Define a minimum, maximum and default number of VM instances 
Create more advanced scale sets with scale out and scale in parameters 
...

-> How do we pick or specify when we need to scale? 

g.1) The simplest way is to look at CPU 
-> CPU is a great indicator to show when your application is under load. 
g.2) We can either configure a scaling policy for a scale set to be manual  eg: we can specify that i need 5 instances 
g.3) Or we can use Full automated autoscaling policy 
g.4) Scaling -> Scaling Policy: Manual | Autoscaling 
	 Minimum number of instances/ Maximum number of instances 
	 
	 Scale out:
	 CPU threshold(%) | Duration in minutes | Number of instances to increase by 
	 
	 Scale in :
	 CPU threshold(%) | No of instances to decrease by 
	 
	 -> Scale out means increasing number of virtual machines 
	 -> Scale in means decreasing number of virtual machines 
	 
g.5) This is a great way of containing cost: both because when there is no load, we keep instances low   and we can also cap the number of instances to have maximum threshold on the cost. 


h) Demonstration - Virtual machine scaling 
-> Configure virtual machine scale sets 
-> Review manual scaling, scale-in policies and custom scaling options 

h.1) Go to Azure portal. Search for "Virtual machine scale sets" -> Create -> Create a virtual machine scale set 

BASICS: 
Project Details : Subscription / Resource group 

Scale set details: 
Virtual machine set name | Region  | Availability zone  

Orchestration: 
Orchestration mode : Flexible / Uniform   
Security type: Trusted launch virtual machines 

Instance details:
Image / VM architecture / Size 

Administration account: 
Authentication type: Password/ ssh public key 

Username / SSH public key source 


h.2) Spot:
-> In Azure, we have the ability to make use of spot instances: where we have excess compute  
-> If you are running a scale set and want to make use of the spot instances, where you are able to tolerate a bit of interruption with your workload, we can take a look at them. 

h.3) Scaling 
-> Scaling set is  unique to our virtual machine scale sets 

Initial Instance count | Scaling(Manual /Custom) | Scale-in policy 

-> In custom we have ability to scale up and down based on different thresholds that we set. 

-> Scale out 
CPU threshold/Duration in min/Number of instances to increase by 

-> Scale in 
CPU threshold/Duration in min/Number of instances to decrease by 

-> Scale-in policy 

i) Review+ Create 

j) Recap:
-> Availability sets allow us to distribute virtual machines across multiple physical pieces of hardware to ensure up time in case something unexpected goes wrong 
-> We also have access to scale sets which keep your application when demand increases 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-22 end 


23) AZ-104 Configure Azure App Service Plans (23 of 31)

AZ-104T00A Administer PaaS Compute Options 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-23

Learn how to configure an Azure App Service plan, including pricing and scaling.


--> In this module, we will see Paas - Platform a a service compute options which are alternatives to virtual machines 

-> First place we will start is the App Service Plans  


LEARNING OBJECTIVES:
-> Implement Azure App service plans 
-> Determine App service plan pricing 
-> Scale up and Scale out the App Service Plan 
-> Configure App service plan Scaling 
-> Demonstration - Configure Azure App service plans 

a) Implement App Service plans

...
-> Determine performance,price and features 
-> Defines a set of compute resources for a web app to run 
● Region where compute resources will be created 
● No of virtual machine instances 
● Size of virtual machine instances 
● Pricing tier 
-> Once or more apps can be configured to run in the same app service plan 

...
 
-> An app service plan allows you to select a number of different options that are similar to what you would pick with a virtual machine 
-> We still pick a region where compute resources will be deployed. 
-> We are still picking the amount of instances you require in the back end 
-> Pick the size of those virtual machines  
-> ADDITIONALLY we pick the pricing tier depending on your availability requirements 

a.1) The difference here is: When you choose to run an application on an app service plan,you dont need to manage the operating system or the underlying components   that usually fall as part of Virtual machine structure 
a.2) We can run multiple applications on an app service plan 

b) Determine App service plan pricing 
Free/
Shared(dev/test)/
Basic(dedicated dev/test),
Standard(Production workloads), Premium(Enhanced scale and performance) ,
Isolated (high-performance, security and isolation) 

b.1) If your application is fine to run in shared compute infrastructure space, look to use either free or shared space. 
d.2) Shared is primarily for dev/test environent 
-> It can support upto 100 simultaneous applications within an app service plan 
-> 1 GB of temporary disc space . Can use storage accounts or other  storage disks for additional storage 
-> Allows simple and cheap option for running your resources 

c) For majority of workloads, we need some sort of dedicated compute in backend 
-> Hence we go to basic, standard or premium plan for majority of customers 
-> Each one offers different scaling options and different number of instances 
d) Basic for devtest work load and supports upto 3 simultaneous instances in backend 
e) Standard and premium offer 10 and 30 instances respectively
-> With ability to scale up and down in form of auto scaling option 

f) Isolated: 
-> Isolated applications come in the form of an app service environment(ASE) 
-> ASE tells that: I wan the whole rack , so give me everything 
-> Pefect when we need many instances and have huge hardware requirements 
-> Also have some interesting options for Virtual network isolation 
-> Thus for high performace computing and for applications that have particularly big requirements , isolated is a great option .

....

Shared compute: Free/Shared.
Runs Apps on same azure VM as other app services apps and resources cannot scale out 

Dedicated compute:(Basic/Standard/Premium) 
-> Runs apps in same plan in dedicated azure vms 

Isolated: 
Runs apps on dedicated azure Vms in dedicated azure virtual networks 

... 

g) Scale up and Scale out the app service plan: 

App service plans comes with few different options for scaling 


g.1) Two mechanisms of scaling: 
Scaling up and Down 
Scaling In and Out 

...
Scale up(Change app service plan) 
● More hardware(CPU, memory,disk) 
● More features(dedicated virtual machines, staging slots, autoscaling) 

Scale out(Increase the number of VMS instances ) :
● Manual (Fixed no of instances) 
● Auto scale(based on predefined rules and schedules) 


g.2) Scale up(Change the App service plan) 
-> When you scale up, we are picking a bigger virtual machine to run your applicatons 
-> hence more hardware with cpu or memory 



g.3) Scale out means adding more instances of virtual machines 
-> Useful when we want to meet demands of customers and keep costs low whend demand is low 

h) Configure App service plan scaling:
-> Scale based on memory, no of web requests we receive 
-> We can scale according to schedules(Weekdays, weekeends, times, holidays) 
-> Combine multiple rules together 
-> if you configure a scale out rule, dont forget to configure a mapping scale in rule 
...
Adjusts available resources based on current demand 
Improves availability and fault tolerance 
Scale based on a metric(CPU percentage, memory percentage, http requests) 
Scale according to a schedule(Weekdays, weekends, times, holidays) 
Can implement multiple rules - combine metrics and schedules 
Dont forget to scale in 

...

i) Lets jump to portal and create compute hosting environment in the form of this app  service plan
-> configure different scaling options 
 etc 

Demonstration 
-> Create and deploy a simple app service plan
-> Review scaling options  


j) In Azure Portal -> Dashboard -> Search "App Service" and we get our "App Service plans" 
j.1) Create 

Project Details -> Subscription / Resource group

App Service Plan details -> Name / Operating System /Region 
Pricing Tier -> Pricing Plan -> Explore Pricing Plan -> Hardware view | Feature View 
-> App Service plan can be configured in zone redundant configuration if availability zones are in your region of choice  

j.2) In app service plan, we can see no of performance statistics available like : CPU percentage, memory  by percentage, Data in etc 
j.3) Good to scale up before deploying applications, but scaling up can be done on the fly also by clicking Upgrade pricing plan 
j.4) We have Autoscale setting also by rules 

-> common rule is CPU percentage 

k) Recap
-> App service plan is the place to host your applications 
-> Providing us the code, we manage the back end compute. 
-> Still we can dictate how much compute you need, what features you require, size of virtual machines   etc 
-> Thus In App service plan , we get the machine in a managed state ready for us to make use and load your applications  


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-23 end 



24) AZ-104 Admninister PaaS Compute Options  :Configure Azure App Service (24 of 31) - 

-> Learn how to configure and monitor Azure App Service instances, including deployment slots.


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-24



Learning Objectives : 
Implement Azure App service 
Create an App service 
Create Deployment slots 
Add Deployment slots 
Secure an APP service 
Create Custom domain names 
Back up an app service 
Demonstration - Azure app services 



a) Implement Azure App Service 
-> App services sitting in Azure - You provide us the code, we provide the hardware in the backend 
-> This means that there is no virtual machine for you to manage 
-> This is a true platform as a service offering where developers have all of the empowerment to run their code without having to worry about patching and infrastructure sitting in the backend 
-> App Services are production ready and are built for enterprise grade security with great compliance options and availability for assessments as well. 

....
Includes web app,s API apps, mobile apps and functions apps
Fully managed environment, enabling high productivity development 
Patform as a service(PaaS) offering for building and deploying hit available cloud apps for web and mobile 
Platform handles infrastructure so developers focus on core web apps and services 
Developer productivity using .NEt, .NEt Core, Java, Python and host of others 
Provides enterprise-grade security and compliance 
....


b) Create an App Service 
b.1) Steps involve creating an app service and then telling us where you want to run that. This is done on an App Service plan 
-> Plan being the backend compute we manage to run for you 
b.2) These app service plans can be fully configured by you, to fit your scaling requirements, cost requirements etc. 
b.3) In terms of what you need from the app service side of things - the code or the container that you wish to run . It is your call on how you want to have  . We can deploy code within your 
environment - but as long as we can select a runtime stack that works for you, you are in good shape 

...
-> Name must be unique 
Access using azurewebsites.net - can map to a custom domain 
Publish Code(runtime stack) 
Publish Docker Container 
Linux or Windows 
Region Closest to users 
App service plan 
...



c) Create Deployment slots 
->  There are a number of different ways we can deploy plans, but one of the things that we look in app service plans of : Standard and above is to use Deployment slots 


Service Plan    				Slots 
Free, Shared, Basic 		      0
Standard						Upto 5 
Premium 						Upto 20 
Isolated 						Upto 20 


Continuous deployment with Stage slot 

Developer 1 -------
				   |
				   |----------> Github ---> [Staging] <---------swap-------> [ Production ]
				   |
Developer 2 --------


c.1) The way it works: You push new code that you update to your repository 
c.2) Then it will go through its requisite checks before moving on to the app service plan 
-> There is native integrations with Github actions  and Azure devops to integrate directly with these app services 
c.3) This code from github gets pushed into a staging slot and when you are ready, you will swap staging and production slots 
-> This means that new updates to code can be implemented as quickly as possible 
-> We can redirect customers and redirect users of application to the latest version of your code in the simplest and quickest manner  
c.4) What is really useful about deployment slots? 
-> If something goes wrong, the code does not work as intended , we can fall back to a last know good state 
c.5) Deployment slots are a great way to manage your code and ensure that your application stays up and running while still empowering your developers to make quick changes and improvements in a much more 
rapid fashion.  


...
Deploy to a different deployment slots (depends on service plan) 
Validate changes before sending to production 
Deployment slots are live apps with their own host names 
Avoids a cold start - eliminates down tie 
Fallback  to a last known good site. 
Autoswap when pre-swap validation is not needed 
... 


d) Add Deployment slots 
-> To add deployment slots you will first define the first slot  like Production slot 
-> Once we have this production slot, we can start to clone from it and create new versions of other slots 
-> You can have multiple versions of a site running simultaneously and we can redirect portions of traffic to different versions 

d.1) lets say we have three slots running:  one for development, one for production and one for live testing 
-> We can send 100% users through to production  or we can put 95% to production and 5% of users to new piece of code we have made ie. testing slot 
-> We can use these different deployment slots for a range of different reasons and swap actions still functions as part of this. 
d.2) Thus deployment slots is a great way to have different versions of a site running simultaneously and verify that things are improving over time. 

...
Select whether to clone an app configuration from another deployment slot 
When you clone pay attention to the settings 
-> Slot specific app settings and connection settings 
-> Continuous deployment settings 
-> App service authentication settings 
Not All settings are sticky(endpoints, custom domain names, SSL certificates, scaling) 
Review and edit your settings before swapping 
... 

e) Secure an App service 
-> Beyond the deployment of an app itself, app service has some interesting features like:
   Ability to integrate authentication  
   
e.1) By default an app service is anonymous 
e.2) We can people to applicationa and then choose to add traditional layers of authentication after that. 
e.3) We can integrate directly with the authentication stack that is included in Entra ID  natively with an app service 
e.4) Allow people to login using microsoft account or an Oauth Provider such as facebook or google and then be able to access your application or site that way 
e.5) this is an interesting way to add authentication layers into your application in a seamless manner

e.6) Security features like: ability to add SSL certificates to your site code natively within the app service hosting environment. 
e.7) Have full integration with Azure keyvault to store secrets 


...
Authentication 
-> Enable Authentication -default anonymous 
-> Login with a third party identity provider 

Security 
-> Troubleshoot with diagnostic logs - failed requests, app logging 
-> Add an ssl certificate - https 
-> Define a priority ordered allow/deny list to control network access to the app 
-> Store secrets in azure key vault 
...


f) Create Custom Domain Names: 
-> Custom domain names are fully supported with app services 
-> There is a validation process, We need to work with DNS registry or domain name provider in order to fully utilize them 
-> By creating custom domain names, it is easy way to push your applications to the broader world 

...
Redirect the default web app url 
Validate custom domain in azure 
Use the dns registry for your domain provider - create a CNAME or a Record with the mapping 
Ensure App service plan supports custom domains  
...
 
 
g) Backup an App Service:
-> Azure app services have their own backup setup 
-> Natively within an app service, we can target specific applications that we are hosting for backups upto 10 GB.   
-> This backup is not just for app itself 

g.1) Azure also supports backing up of database content. 

-> 10 GB for a database is relatively small. 
-> Intent here is , if there is an application and may be some core or core parts for running the app - we would target both the app and database related to that. 
g.2) If the customer database is multi TB size ,  we have plenty of other backup mechanisms 
-> But if it is related to the application configuration itself - this is a simple way to ensure that everything is included together. 

g.3) During restoration - we can choose to restore to a previous state or simply recreate the application based on a backup into a new slot 
-> Hence there are plenty of ways to bring things back including exclusion options to ensure that we are not targeting things that you dont need to backup or restore. like Temporary files or bits of configuration stored elsewhere 

g.4) App service is an all in one feature, it has: Authentication, Authorization, insights , backup etc 

...
-> Create app backups manually or on a schedule 
-> Backup the configuration, file content and database connected to the app 
-> Requires standard or premium plan 
-> Backups can be upto 10 GB of app and database content 
-> Configure partial backups and exclude items from backup 
-> Restore your app on-demand to a previous state or create a new app 
...


h) Demonstration - Configure Azure app services 
-> Create a web app in azure portal 
-> Verify if the web app is running 
-> Explore deployment slots 


h.1) Goto Azure portal and search for "App Services" -> Create 
h.2) Through create we can create applications of different types like:
Web App 
Static Web App 
Wep App + Database 
WordPress on App Service 
h.3) Lets choose to create standard "Web App" here 

h.4) Basics 
-> Project Details -> Subscription/Resourcegroup 

-> Instance Details:
--> Name (Name of web app we are going to create 
--> Publish (This is where, we are going to source the code that we are going to run) i.e from where we are going to publish the application 

h.4.1) Publish has three options: 
Code | Docker Container | Static Web App 
-> If we select code, which is codebase then we need to select a runtime 
-> If we select Docker Container , if it is contained within a container 
-> Static webapp  
-> Here lets select Code 

h.4.2) Regions 
h.4.3) Pricing plans 
Windows Plan | Pricing Plan 

-> These are about the hosting environment that we are going to use 
-> App service plans support more than one application at a time 

h.5) Deployment tab 
-> Next we need to select the deployment that we wish to happen 
-> This is where we do integration with Github actions or with Azure devops 

Github Actions Setiings -> Continuous deployment Disable|Enable 

Github Actions details -> Github account | Organization 

h.6) Networking 
-> There are two options in standard app service: a) Do you wish people to access this site publicly b) Do you wish to integrate with a virtual network .
-> This can be done by turning On or Off this option: Enable Public Access 

Enable network injection 

h.7) Monitoring 

h.7) Review + Create 

i) Once creation process is done, we will be in the App Service screen for that particular Web app :
We will be able to see the following:
-> App Service Plan 
-> App status on whether it is up and running 
-> Operating System and other details like default domain. Before you select default domain, every app service you launch will have its own domain. 


j) From this point, we have few different options: 
-> We can start deploying code to this app, if we have that available or start configuring deployment slots

j.1) To configure Deployment slops, in Web app of App service, go to deployment section tab 
-> Here we can add slot for production or any other environment 
-> We can also set traffic % here 

j.2) Deployment slots -> Add  Slot -> Name|Clone Settings from (already created one will be listing) 
 j.3) Once we create new slot, we can see that it creates a secondary url 
 -> lets call this slot as green in blue green deployment 
 j.4) After creating slot, we can choose to divide the traffic 
 j.5) We can swap slots here with source and target options 
 
 k) Recap 
 -> Azure app services allow you to run the code that you have developed and you are able to provide the code  to microsoft azure and Azure manages the run time environment and the backend compute for you
-> We can easily scale the backend to meet your demands and ensure that your application is up and running 
-> Ability to use deployment slots for testing and roll back if there is any issue , is extremely useful for developers to make  rapid changes in environment and make environments quicker 

 https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-24 end 
 
 
 
25) AZ-104 Configure Azure Container Instances (25 of 31)

-> Learn how to configure Azure Container Instances including container groups.

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-25 start 

-> AZ-104T00A Administer PaaS Compute Options 

-> In this module, we will look at Platform as a Service compute options - things that are alternative to virtual machine infrastructure 
-> In particular we will look at how to run containers in cloud without having to host the underlying compute. i.e the Virtual machine 


Learning Objectives:
Compare Containers to Virtual Machines 
Explore Azure Container Instances Benefits 
Implement Container Groups 
Demonstration - Configure Azure Container Instances 
Manage Containers with Azure Container Apps 
Demonstation - Configure Container Apps 

a) Compare Containers to Virtual Machines 
-> Lets see what is a container and why we use them compared to virtual machines 

a.1) What is a container ?
-> Containers are a subdivisions of a machine, beyond what we do with virtual machines  
a.2) If we think about the way that physical hardware works : Server/Host OS 

-> We have a physical server running an Operating System eg: windows server 2022 
-> Here Windows Server 2022 is Host OS 

a.3) A virtual machine runs on top of this baseline server 
a.4) We use a hypervisor to pass through disk information,networking information and everything we need  for a VM's Guest OS from Host OS 
a.5) Each Virtual Machines need operating systems themselves which is Guest OS.
-> Thus mutliple VM's run Multiple Guest OS 
a.6) BY DOING THIS, WE CONSUME A LOT OF COMPUTE 



########
Server->Host OS -> Docker Engine(Container) | Hypervisor(VM) 


.DockerEngine -> Container1[AppA with Bins/Libs]
.DockerEngine -> Container2[AppB with Bins/Libs]


.Hypervisor->VM1[Guest OS ->AppA with Bins/Libs]
.Hypervisor->VM2[Guest OS ->AppB with Bins/Libs]

########

b) To solve this problem of multiple Guest OS consuming lot of Compute, Containers offer an interesting alternative 

b.1) In Containers also we have the same Physical hardware of Server/Host OS 
b.2) But here instead of Hypervisor, we have Docker Engine 
DOCKER ENGINE
b.3) Docker Engine is an orchestration engine that talks to containers running on hardwares and allows us to know whats happening there 
-> Like being able to say, when things need to be spun up, spun down and pass along resources
b.4) Importantly: Docker engine  passes actions from Applications present within containers : Container1[AppA with Bins/Libs] to the Host OS 
b.5) This means that we dont have to run a secondary OS[GuestOS] like VM approach and containers uses comparably less compute individually 

b.6) What is present within application present her: Container1[AppA with Bins/Libs]

-> The application contains its code, its binaries and its all the things that app needs in order to run which is contained in one neat little package. 

-> Hence the name container 

Container->App A -> Bins/Libs 

c) Other advantages of using containers:
c.1) Designing applications using container approach on compared to VM approach makes them very fault tolerant 

##
Persistent storage is a file-share container managed by Azure and allocated per application. All instances of an application share data stored in persistent storage. An Azure Spring Apps instance can have a maximum of 10 applications with persistent storage enabled
##

-> If Application A goes down in a particular container, we simply spin up another container . We can keep persistent storage elsewhere and ensure that things are deployed rapidly 
c.2) If application B gets crashed , it does not affect application at all, there is isolation between each one of these applications. 
c.3)  Hence container is a great alternative to Virtual machines and its the one that is used in modern scaling applications 


..
Isolation
Operating System 
Deployment 
Persistent storage 
Fault tolerance 
.. 



d) Explore Azure Container Instances Benefits 
d.1) Within Azure we have few different ways to host containers 
d.2) First we are going to look at Azure Container Instances, because if you are looking at quickest possible way to run a single container in cloud , without managing any compute of any type 

d.3) All we need to do is:
► tell amount of RAM needed, 
► no of CPU cores required, 
► Where your container is located 
-> Then it will be booted up in seconds 

d.4)  We support both Linux and Windows Containers 
d.5) Suppose all standard APIs for Storage to access a file share : Persistent storage 
d.6) There are also mechanisms to deploy into your Virtual network with container instances 

[Virtual Network--> ContainerHost[Container[Webserver with port80]]]--> Port80(with Public IP address) 



...
PaaS Service 
Fast startup times 
Public IP connectivity and DNS name 
Isolation features 
Custom sizes 
Persistent storage 
Linux and windows containers 
Co-Scheduled groups 
Virtual network deployment 
... 


e) Implement Container groups:
-> One option we have for orchestration of multiple individual containers is the container group
-> We can run weather component of container application and  the backend database components as two separate applications  
-> But by adding them in as a container group - we ensure that they are always booted up together on the same host. 
-> To keep latency low and ensure everything is working well, it is  a super useful way to have lifecyle of app application remain the same no matter what is going on 
-> This is perfect, if you need to have consistent storage and have consistent resources to be spun up simultaneously 
-> Here the port 1433 is exposed internally to the container group, but not exposed outwards.  Hence people can access the app through that front end, but nowhere else 
-> Hence this is very useful way to have an application spin up everything it needs, simultaneously without going into complex orchestration routines 


Azure Files---{Container group [Container+web]}----Port80.......>DNS name and IP address 

Azure Files ----Container ----1433


...
 Top level resource in Azure container instances 
 A collection of containers that get scheduled on the same host
 The containers in the group share a lifecycle, resoures, local network and storage volumes 
 ...
 
 
 f) Demonstration - Configure Azure Container Instances :
 -> Create and configure a container instance 
 -> Verify deployment of the container instance. 
 
f.1) In Azure dashboard search for "Container instances"  and + Create

f.2) In Basics, 
f.3) Project Details -> Subscription+ Resource group 
f.4) Container Details -> 
Container name :
Region:
Availability Zones(Preview): 
SKU :
Image source :
Run with Azure Spot discount
Image: 
Size: 

f.5) Networking: 
Networking type: Public| Private 
DNS name label:
DNS name label scope reuse :
Ports:   Ports/ Ports Protocol 

f.6) Advanced:
Restart Policy : Restart on failure 
-> if a container fails and an application crashes, what do you want it to do? Do you want container to restart or stay offline. Each customer requirement will be different. we need to set it accordingly
Environment variables :
Command Override:
Key management: Microsoft managed keys(MMK) |Customer managed keys(CMK)

f.7) Review + Create  
-> After hitting review+ create - container will be up and running shortly 

f.8) 
-> Now we will be able to access the application running inside the container 


g) Manage Containers with Azure Container apps: 
-> Thus container instance is perfect if you just need to run that single or one or two containers together.  
-> If you have something more complex in containers , where multiple pieces of an application that we need to be able to work together and do different things and orchestrate all that stuff. 
-> In that case, Azure container apps is the alternative. 
g.1) Azure container apps is an interesting way of being able to deploy multiple containers together 
g.2) We can uses this easily as an alternative to Azure kubernetes service 
g.3) Azure container apps allows you to have simplified infrastructure  development for a multi container application with individual components scaling up and down as required. 
g.4) Azure container apps is also fully featured in terms of integration with Azure container registry, where we are using custom deployments that are noted with registry here 

...
Alternative to Azure kubernetes service 
Integrates with Azure container registry 
Simplifies complex infrastructures 
Manages Container orchestration
...



h) Demonstration: Configure Azure container groups 
-> Create and deploy a container app. 
-> Verify if application url displays welcome message 

h.1) In Azure portal -> Search "Container Apps" + Create 

h.2)Basics 

Project details: Subscription/Resource group / Container app name  :

Container Apps Environment : 
Region 
Container Apps Environment 

h.3) Container tab:
Quick start image:

Container resource allocation 
-> Here CPU core and memory size already put in place. 

Application ingress settings:
Ingress:
Ingress traffic 
Target port 

i) Review + Create 

j) After deployment is complete, we can configure some more in container apps 

Application -> Containers 
k) ALso we will be able to see our applicaiton in containers coming up 

l) Recap:
-> Couple of options for hosting containers in cloud 
1)  Container instances perfect for single containers you wish to run.   
2) And Container apps a greay way for orchestrating multiple containers together.  

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-25 end 


26) AZ-104 Configure File and Folder Backup (26 of 31)

-> Learn how to configure backup and restore policies that meet your company's regulatory needs.

AZ-104T00A Administer data protection 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-26

-> We will look at ways to back up your file.
-> File and folder backups need to be configured in a different way compared to virtual machines 

Learning Objectives:
-> Describe Azure backup benefits 
-> Implement Azure backup center 
-> Setup recovery service using Vault backup options 
-> Demonstration - backup azure files shares 
-> Configure on-premises file and folder backups 
-> Manage Microsoft Azure recovery services agent MARS
-> Demonstration - backup files and folders 


a) Describe Azure Backup benefits 
-> Azure backup service is the native cloud backup solution that works across all our centers 

...
Automatic storage management 
Multiple storage options 
Unlimited data transfer 
Data encryption 
Application consistent backup 
Long term retention 
...



b) Implement Azure backup center 
b.1) Azure backup center is the single pane of glass to manage your backups across all environments in one location 
b.2) Focussed on collecting data from multiple sources 
b.3) Not only looking at failed versus successful backups but also looking at mechanisms to allow to assist with testing and get reporting to know things are working well. 
b.4) Also has  Integration with compliance options   which are useful for clients to make sure things are working correctly 
b.5) If you are looking for management center for your backup system on MARs , this si a great option to look at. 


...
-> Single pane of glass to manage backups across a large and distributed azure environment 
_> Datasource centric managment focussd on what you are backing up 
-> Connected experiences with native integrations that enables management at scale 
...


c) Demonstration - Backup Azure file shares 
-> Create a recovery services vault 
-> Configure file share backup 

c.1) In portal serach for "Backup center"  and click + Backup
-> Two types of vaults available. 

-> A vault is an entity that stores the backups and restore points created over time. The vault also contains the backup policies that are associated with the protected virtual machines 
-> Proceed to vault creation by selecting vault type 

c.2) Recovery Services vault(RSV) 
-> Supported datasources 
Azure Virtual machines 
SQL in azure VM 
Azure Files(Azure storage) 
SAP hana in azure VM 
Azure Backup server 
Azure backup agent 
DPM 


c.3) Backup Vault 



-> Supported datasources 

Azure disks
Azure blobs(Azure storage) 
Azure database for postgreSQL users 
Kubernetes services(preview) 


c.4) Creating Recovery Services Vault
Basics: 
Project details: Subscription/Resourcegroup 
Instance details: Vault name/ region 

Vault properties: 
-> Enable immutability means changes cannot be made to backups 

NEtworking:
-> you wish to have access from all networks or only allow specific private networks access. 

Connectivity Method: 
-> You can connect to this recovery services vault either publicly via public IP address or privately using a private endpoint 

Allow public access from all networks 
Deny public access and allow private access 
c.5) review + create 
-> This will lead to Recovery services vault page 

c.6) Only here we are going to do actual backup 
-> We need to select storage account we wish to back and other things 
-> This can be done through blade on left under the "settings" -> Properties 

c.7) Settings-> Properties 
-> Here we can select type of replication we wish ? 

-> Selecting storage replication type whether : Locally-redundant or Zone-redundant or geo-redundant is import before you begin to back up things 

c.8) On selectin + Backup -> Backup Goal 
-> Where is your workload running 
-> What od you want to backend? 


-> Then click backup -> Storage account? 
-> Fileshares to Backup 
Name Azure file share type 

Policy Details:
Backup policy | Full backup

-> By default frequency of backup is daily policy on first run through the wizard 

c.9) We have daily and hourly backups available  and also we can choose Retention time of daily backuup point. 

c.10) Last thing to do is: to wait for the first backup to kick off  or we can manually begin the first backup to ensure that things are going to be backed up from here. 


d) Once deployed, now in Recovery services vault page, under getting started section there will be Protected Items -> Backup Items 
-> On clicking backup items,we can see exactly what is currently being backed up 
 it shows 
 
 Backup MANAGEMENT TYPE | BACKUP ITEM COUNT 
 
e) Until now we saw,how to backup Azure workloads like things on Azure : Virtual machine / Azure fileshare / SQL server in Azure VM / SAP HANA in Azure Fileshare 

f) How to backup if files and folders are located on-premises? 
-> That can also be done in RSV 
-> Setup is pretty much same, but we need to select few different things in wizard  
 
 
f.1) Earlier we would have selected 
-> " Where is your workload running" as Azure , now we need to select "On-Premises" 
-> What do you want to backup as "Files and Folders" 

g) COnfiguring on-premises file and folder backup : steps 
-> To configure backup in On premises  we use the "Azure Backup agent" 
-> THis agent requires access to files or folders that you wish to backup . They can be local or can be on network share 
-> Normally files or folders will be in Windows workstation or server 
-> Backup agent periodically based on the schedule, will target files and folders and go through / then synchronize them into your recovery services vault 

g.1) Create Recovery services vault 
g.2) Download the agent and credential file 
g.3) Install and register agent 
g.4) Configure the backup 


h) MANAGE THE MICROSOFT AZURE RECOVERY SERVICES AGENT: 

The configuration can also be done through a central services agent which si MARS agent : Microsoft Azure recovery Services 

h.1) What is more useful on Mars is: It does not require a separate backup server to actually run 
-> We can run this on the server that is going to be doing the backups themselves or it can be running on secondary worker server 
h.2) It is not application aware backup. it is purely focussed on file/folder/volume level restore only


...
Backup or recover files and folders on physical or virtual windows OS(VMs can be on-premises"  or in Azure 
-> No separate backup server required 
-> Not appliction aware: folder file and volume level restore only 
-> No support for linux 
...



i) Recap: 
-> Gone through basics of Azure backup 
-> Focussed on files and folder backup specifically 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-26 end 



27) AZ-104 Configure Virtual Machine Backups (27 of 31) 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-27 start 

Learn how to configure virtual machine backups including restore operations 

Learning Objectives:
Protect Virtual Machine data 
Create virtual machine  snapshots 
Setup recovery services vault backup 
backup virtual machines 
restore virtual machines 
Demonstration - virtual machine backups 
Implement azure backup server 
Compare backup options 
Manage soft delete 
Implement azure site recovery 


a) Protect Virtual Machine Data 
-> There are three ways to prothect your virtual machine data in azure. 

a.1) SNAPSHOTS
Snapshots are for short simple quick restoration of a virtual machine at disk level 
->  They utilize managed disks to achieve this 
-> We look for 1 to 5 day period that we can restore data from these snapshots 
-> Designed for quick retention 


a.2) AZURE BACKUP 
For longer term backups and for anything where you require true application consistent backup, Azure backup is a far better choice  
-> THis retention can be for a significantly longer period of time and we can roll back to multiple different states and restore virtual machines to other locations. 

a.3) AZURE SITE RECOVERY 
-> Azure Site Recovery is focussd more on disaster recovery 
-> It ensures that if an application has a major disaster or a region that you are hosting an application goes completely down -  we are able to keep your application up and running and fail across to a secondary region 
-> Hence even in worst scenarios, your app keeps running 



...
Snapshots: Managed snapshots provide quick and simple option for backing up vms that use managed disks 

Azure Backup: Azure backup supports application consistent backups for both windows and linux vms 

Azure Site Recovery: Azure Site Recovery protects your vms from a mahor disaster scenario when a whole region experiences an outage 
...


Lets begin with snapshots: Create Virtual Snapshots
b) Create Virtual Snapshots

-> A snapshot works by taking a snapshot, just like a photo 

b.1) We are going to take data from disks that are on virtual machine and allow for instant resotration within  a 5 day period. 
-> This is designed for extremely fast rollback. 
b.2) Hence for quick changes to a virtual machine or protection against a quick application change, they are perfect. 


c) Setup Recovery Services vault backup options - VMs 
-> Multiple servers can be protected using same recovery services vault. 

-> A more traditional backup option would be recovery services vault. 

c.1) We do support ability to backup virtual machines in Azure or Virtual machines in on-premises location 
c.2) What is great about how recovery services functions is: that it not only supports raw virtual machines but also HyperV and VMware environments as well as Bare metal server backup 
c.3) Hence no matter where you machines is: whether it be virtual or be physical, we have a guarantee that we will be able to back it up .


d) Backup Virtual Machine 
-> Process of backing up virtual machine is straight forward 
d.1) We need to create a vault some where to store the data. 
d.2) Use the portal to define the backup 
-> This is where we decide how often we are going to backup  and how long we retain the data in this backup format. 
d.3) The third part of setup is the backup of virtual machine itself. 
-> We use an agent installed on the machine that then talks to azure and is able to synchronize its backup data. 

...
1 Create Recovery services vault: 
Use recovery service vault  in the region where you are performing your virtual machine backups and choose a replication strategy for vault 
2 Use the portal to define the backup 
-> Take snapshots(recovery points) of your data at defined intervals. These snapshots are stored in recovery services vaults 
3 For the backup extension  to work, the Azure VM agent  must be installed on Azure virtual machine . 
....


e) Restore Virtual machines:
-> Once your backup is configured, in the backup items list we will be able to see   the virtual machines that you are protecting. 
-> We can trigger backups manually
-> We can restore individual virtual machines 
-> And also open backups to recover single files 

e.1) Anytime the backup service is doing something when you manually trigerred, it will let you know about notifications to make sure if if it is going well. 
e.2) Depending on application that you are backing up and the VM configuration that you are backing up , there are two types of backup available 

APPLICATION CONSISTENT: This is available for certain applications that we have built support for and crash consistent 


...
Restore Virtual Machines
-> Once you trigger restore operation, backup service job creates a job for tracking restore operation 
-> The backup service also creates and temporarily displays notifications, so you monitor how backup is proceeding. 
....



f) Demonstration - Virtual Machine backups 
-> Create a backup for virtual machines 
-> Configure and review backup policy

f.1) In Azure portal dashboard , search for "Backup center" 
-> In backup center we will be able to configure things like: Recovery services fault - where we will be storing our data as well as backup policies  

f.2) In backup center, if we click "Backup" button 

g) Implement Azure backup server 


Specialized workloads(virtual machines/files/folders/volumes)----System center DMPM or Azure backup server----Azure

...
App-aware backups file/folder/volume backups and machine state backups
-> Each machine runs the DPM/MABS protection agenert and the mars agent runs on the MABS/DPM 
-> Flexibility and granular scheduling options 
-> Manage backups for multiple machines in a protection group 
...


h) Compare backup options:
h.1) Between the two virtual machine backup options, Azure Backup agent(MARS) and Azure Backup server(MABS) - it is whether you want to take Virtual machines and full application load or just a series of files and folders. 
h.2) Azure backup agent(MARS) supports only files and folders and has the ability to store its data in a recovery services vault. 
-> Azure backup agent is designed fully for file and folder restoration but it does not require 
the extra server to be able to orchestrate 
h.3) if you are looking for configurability and the ability to have very advanced backups for virtual machines , Azure Backup Server(MABS) for On premises workload will be my preference 
h.4) MABS has much more flexibility in what it can backup, but it still can target files and folders, as well as being able to backup to a recovery services vault 
-> Also able to retain backups locally, which means it can cache data locally before sending to cloud at a later date  


....
Compare Backup options:
AZURE BACKUP(MARS) AGENT: 
a) Benefits:
	Backup files and folders on physical or virtual windows OS 
	No separate backup server required 
	
b) Limits:
	Backup 3x per day 
	Not application aware 
	File, folder and volumen level restore only 
	No support for linux 
	
c) Protects: 
	Files and folders 
	
d) Backup storage:
	Recovery services vault 
	
AZURE BACKUP SERVER(MABS) 
a) Benefits :
	App aware snapshots 
	Full flex for when to backups 
	Recovery granualrity 
	Linux support on Hyper V and VMware VMs 
	Backup and restore VMware VMS 
	Does not require a system center license 
	
b) Limits 
	Cannot backup Oracle workloads 
	Always requires live azure subscription 
	NO support for tape backup 
	
c) Protects 
	Applications 
	Workloads 

d) Backup storage 
	Recovery services vault 
	Locally attached disk 


i) Manage soft delete 
-> Few other backup options which we have not covered so far 
-> First one is Soft Delete 

i.1) Soft delete is a native function that is built into a recovery services vault 
-> As long as your data is looking at the recovery services vault where it is landing, you will be able to enable soft delete
i.2) THink of soft delete like a recycle bin 
-> When you delete something from vaault, think that you delete a vm which you dont want to backup,  azure will keep that virtual machine backup data in a state where it can be undeleted for next 2 weeks. 
i.3) After 14 days backup files are immediately cleared out. 
i.4) Hence no extra action is required to ensure that the maintenance is happening on other end. 

i.5) Soft delete can be disabled too 

...
Backup data is retained for 14 additional days 
Recover soft deleted backup items using an "undelete" operation 
Also available for storage account containers and files shares 
Natively built for all recovery service vaults
... 


j) Implement Azure site recovery 
-> Azure site recovery is a major solution to ensure that application stays up and running  
j.1) Since  it is a virtual machine focussed  and utilizes a failover technique , it is  a great option for protection of VMs 
j.2) There are few different ways that this can be depoyed. 
-> First we will see azure native solution first 
j.3) First and common way that i deployed Azure site recovery is as: DUAL REGION DISASTER RECOVERY SOLUTION 
-> In region1 we will have networking and all virtual machines setup . This is where we send all our users. 
j.4) But what we want is the ability, that if something goes wrong in region1 , like loadbalancer does not work properly or virtual machine stack goes down or big things like entire region goes disappearing 
-> Whatever it is, we can simply hit a button : Azure Site Recovery redirect users to the secondary region
j.5) As it has been constantly replicating every disk write as it happens asynchronously , the virtual machines start up in secondary region 
j.6) This is great and really important feature to ahve when you are looking to protect in true disaster scenarios 
j.7) It has couple of interesting quirks to it 

Region1 and Region2. Its first region need not be Azure . You can use Azure site recovery to be able to fail between on-premises location through the cloud or an AWS instance across to azure. 

-> The core point is: Even if one region is on prem and other region is azure, you can still use Azure site recovery to fail betweent hem 



...
Implement Azure site recovery:
-> Replicate azure VMs from one azure region to another 
-> Replicate on-premises VMware VMs, Hyper-V VMs, Physical servers(windows and Linux), Azure stack VMs to Azure 
-> Replicate AWS windows instances to Azure 
-> Replicate on-premises VMware VMs, Hyper-V VMs managed by System Center VMM and Physical servers to a secondary site. 
...
 
 
 
k) Learning recap :
a) Looked few different components of Virtual machine backups 
b) Azure backup and more importantly azure backup center is your home away from home to configure and ensure that your backups are running correctly 
c) If something is in Azure , it is simple as clicking few tick boxes - if it is on premises,server is available if you want to go down to that level 
d) No matter where your infrastructure is hosted, azure has a mechanism to help you keep those systems and  running   

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-27 end 

28) AZ-104 Configure Azure Monitor (28 of 31)

AZ-104T00A Administer Monitoring 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-28

-> Learn how to configure Azure Monitor, including querying the Azure Monitor activity log.
-> This module is focussed on administration of monitoring platform for getting access to all our monitoring components 

Learning objectives - Configure Azure monitor 
-> Describe Azure monitor key capabilities 
-> Describe Azure monitor components 
-> Define metrics and logs 
-> Identify data types 
-> Describe activity log events 

Azure activity logs: helps to see who is doing what in your environment. 

a) Describel Azure monitor key capabilities 
WHAT IS AZURE MONITOR:
a.1)  Azure monitor does 3 primary things 
		1) Monitoring and Visualization 
		-> Makes use of dashboarding function to eaxactly show how things are behaving 
		-> We can get good visualization data of what is feeding  through in our environment.  
		-> how many times are we seeing things scale 
		-> Are we seeing operation happen where the virtual machine is misbehaving or showing VM is bit unhealthy 
->  All the above capabilites are available in the monitoring and visualization components of Azure monitor 
		2) Query and Analyze logs:
		-> Activity logs , diagnostics logs, different traces and telemetry logs - all of these are contained within a log store that monitor can make use of 
		-> This helps us to do deep analysis as well as deeper visualization above and beyond what we can do with a standard metric 
		
		3) Alerting system: Setup alert and actions 
		-> Alerts allow for automation. So if we are able to trigger based on the data we are finding in  query and analytics component or within metrics component - we can use this to notify people when something is wrong or something needs to happen 
		-> Also this alerting system, allows you to then trigger secondary applications or functions to do things in your environment 
		-> Hence this is the home of automation 

...
Decribe Azre monitor key capabilities:
MONITOR AND VISUALIZE METRICS 
-> Metrics are numerical values available from azure resources helping you understand the health operation and peformance of your systems 
--> Core monitoring for azure services 

QUERY AND ANALYZE LOGS:
-> Logs are activity logs, diagnostic logs  and telemetry from monitoring solutions. 
-> Analytics queries help with troubleshooting and visualizations 

--> Collects metrics, activity logs and diagnostic logs 

SETUP ALERT AND ACTIONS 
-> Alerts notify you of critical conditions and potentially take corrective automated actions based on trigger from metrics or logs 
-> Used for time critical alerts and notifications 
...
		


b) Understand Azure Monitor Components:

b.1) Monitor is made up of many different pieces 

-> On the left we have our datasources like Azure Platform, Virtual machine etc.  

b.2) Data sources feed into Azure monitor to infom things. 
b.3) Once monitor receives data feed from datasources, it stores within its data platform - a whole range of different things like: Metrics/logs/traces and changes to the environment as well 
b.4) Once you get that data into the platform , we can use it for insights, visualization etc 
b.5) Insights: These are useful for specific application workloads and specific people in an environment. 
    ● Network Insights 
	● Container Insights 
	● Application Insights 
	-> These are great examples of being able to get further data and specifically data that is focussed on different solution areas. 
	
b.6) Visualization/Dashboarding:
	● Can create workboards , dashboards and also have native integration with both Power BI and Grafana 
b.7) Analyze:
	● Whether it is metrics/changes or logs that you are monitoring for: Azure monitor has access to all of the analytics platform components that you require to know what's happening 
b.8) Response:
	● Within response space, alerts and actions live. And also Authoscaling . 
	● We use Azure monitor backend to scale virtual machines up and down. 
b.9) Integration:
	● This is where you have complete control of what you would like to do next 
	● Have full integration with Event hub to take the data and respond to it in whatever way we want and orchestrate to ther components of Azure. 
	● Have full access to Logic Apps: which is a low code solution to define what you would like to happen next. 
	● If you dont have solution within suite of tools in Azure, Import/export APIs helps to integrate with Azure monitor natively through your rest APIs 
	● Thus we can integrate with any third party application 
	
...Understanding Azure monitor components 
-> Application monitoring data 
-> Guest OS monitoring 
-> Azure resource monitoring 
-> Azure subscription monitoring 
-> Azure tenant monitoring 
.....

....azure monitor....


Data Source: Application/Infrastructure/Azure platform/Custom sources 

Data platform: Metrics /Logs/Traces/Changes 

Insights: Application/container/VM/Network 

Visualize: Workbooks/Dashboards/PowerBI/Grafana 

Analyze: Metric explorere , Log Analytics, Change Analysis 

Respond: Alerts and Actions/Autoscale 

Integrate: Event Hubg/ Logic Apps/Import and Export APIs 

....azure monitor....



c) Define Metrics and Logs 
-> Monitor has two primary sources of data 
c.1) METRICS 
-> First is Metrics: Metrics are numerical values that describe some aspect of a system at a point in time . 
Eg: CPU usage at last second, Network usage over the last five minutes, Amount of space left on a hard drive,  
-> Thus numbers that are lightweight and easy for us to respond to . Lightweight means not a lot of compute power required, 

c.2) LOGS:
-> Logs contain different kinds of data organized into records with different sets of properties for each type. 
-> Logs are deeper , they are text based information ways of analysing and recutting data in multiple fashions  to get different insights 
-> Lot of different ways to use logs 
-> Security teams and infrastructure teams use them for analysis and trying to understand where something might have gone wrong.  
-> Developers use logs to debug and get further information about how application is performing above and beyond what is being shown in metrics numbers 

d) Majority of things that you bring into logworkspace are: 
Application: Application logs/ Diagnostic logs 
Resource: Diagnostic logs / Activity logs 
Host VM: Activity Logs

e) Describe activity log events:
-> For infrastructure that is compute and non-compute, we have access to the activity logs  
-> What are ACTIVITY logs:
---> List of every action that someone has taken in your azure environment: What API they hit,  what they did with that data,whehter they are allowed or denied to  etc 
-> so every single time someone has logged into portal or CLI or powershell does an action , it is in the activity log 
-> if you want to know exactly how people have been doing or be able to analyze things or to have audit trail, we can find it in activity log  
 It is easy to be able to archive the data out to a storage account or to move it into same workspace where we are storing all logs more generally 


...
Send data to log analytics for advanced search and alerts 
Query or manage events in portal, powershell, cli and rest api 
Stream information to Event Hub 
Archive data to storage account 
Analyze data with Power BI 
...  


f) Query the Activity Log:
-> Within activity log , there are few different ways that we can cut the data 
-> We can fiter by different resources or management groups or subscriptions by adding filters 


..
Filter by Management group, subscription, timespan and Event Severity 
Add a filter, like Event Category(Security, Recommendations, alerts) 
Pin Current filters and download as CSV
...


g) Recap:
-> Azure monitor is your central hub to maintain logs . Thus we can analyze our azure infrastructure using Azure monitor logs 
-> Monitor the performance of virtual machines using azure monitor insights 
-> Monitor, diagnose and troubleshoot your azure storage 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-28 end 


29) AZ-104 Configure Azure Alerts (29 of 31)

-> AZ-104T00A Administer Monitoring 

-> Learn how to configure Azure alerts including action groups.


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-29

Learning Objectives:
Manage Azure monitor Alerts 
Create Alert Rules 
Create Action Groups 
Demonstration - Alerts 

a) Manage Azure Monitor Alerts: 
Azure Monitor is our home whenever we need to dive into any monitoring solution in Azure. 
-> Hence alerts also live in Azure Monitor
a.1) Alerts rely on the data, we gather through our monitoring infrastructure. 
-> Hence we use the Azure monitor alerts page to categorize different alerts that are coming through 

...
Unified Authoring experience 
Displayed by severity 
Categorized by new, Acknowledged and closed
... 


b) Demonstration - Alerts 
-> Create and configure an alert rule 
-> Review alerts 

b.1) In azure dashboard, search for "monitor" service and we will go to monitor service page. 
-> In the left of the blade, we can see the alerts in monitor page 
-> Alerts page shows the alerts in our environment
b.2) To create alerts-> Create -> Alert rule 
b.3) While creating alert rule:

1) Select the resources in resource selection screen in scope
-> We can select a virtual machine, storage account or virtual network etc
2) Condition 

Signal -> We need to select a signal 

3) Actions 
-> Select Action Groups or Create Action groups 

-> Action group is a set of actions that can be applied on an alert rule. 

-> By creating action group, we can see what options you have which is available for automation 

Subscription/Resourcegroup/Region 

Instance details:
Action group name/ Display name 


4) Notifications in action group 
5) Actions in Action group 
Action type/Name 

Action Can be:kicking off azure function, automation runbook, event hub itsm, secure webhoot, logicapp etc

b.5) Review+ Create

-> Once this is done, we will get relevant alerts 

c)Recap:
-> Azure alerts is an automation system that allow us to trigger data based on conditions that are coming through and orchestrate other parts of our environment. 
-> Improve incident response with alerting on azure 
-> Configure for alerts and detections in microsoft defender for endpoint 
-> Manage alerts and incidents in microsoft defender for Endpoint 
-> Remediate security alerts using microsoft defender for cloud. 


https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-29 end 



30) AZ-104 Configure Log Analytics (30 of 31)
-> You will learn how to configure Log Analytics including structuring queries.

-> AZ-104T00A Administer monitoring 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-30 


-> Log Analytics workspace is where we keep our logs in azure monitor 
-> Hence we need to know how it functions and how we can query the logs that are located there. 


Learning Objectives:
Determine Log Analytics uses
Create a workspace 
Query log Analytics data 
Structure Log analytics queries 
Demonstration - Log Analytics 


a) Determine Log analytics uses 

a.1) Why do we use log analytics:
-> Log analytics is both data lake for our logs and also query system 
-> Incredibly fast to query over large amounts of data and get insights in a quick and easy manner 
a.2) In addition Log analytics has unique language which allows for building efficient queries itself 
-> hence it is great way to look through an environment, whether it is secuirty landscape or infrastructure analysis landscape or general diagnostics 
a.3) The queries that we built using log analytics can also be used for automation,alerting and whole range of different systems. 
-> hence it is great place to store your logs 
a.4) The way we store those logs is by creating a workspace. 
a.5) The log analytics workspace is where you want to store metrics, logs and various types of data.  
-> You can choose to have multiple workspaces per subscription 
-> You can choose to have one workspace  or one per region 
a.6) Regardless of what you choose, once you  start we are able to start filling data in and querying the data that is located within your workspace.  





...
-> A service that helps you collect and analyze data generated by resources in your cloud and on-premises environments
-> Write log queries and interactively analyze their results 

--> Examples include assessing system updates adn troubleshooting operational incidents 
...


b) Query Log Analytics data 
-> The query language that we use is  roughly a  combination of  powershell and SQL 
-> Since it is quick manner for retrieving data and to work with it, the data we retrieve out can be brought elsewhere for future analysis. 
-. BEcause of native integration with Power BI and  with Grafana that Azure monitor has , Azure monitor uses log analytics workspace as its data store - we can easily integrate those queries straight and pull data into a secondary location
-> Also we can export it to excel.  
-> Log analytics follow a clear and common structure. 

..
Common queries and query language(KQL) for custom searches 
Quickly retrieve and consolidate data in the repository 
Save or have log searches run automatically to create an alert 
Export data to power BI or excel 
...


c) Strucutre Log Analytics Queries 
c.1) The first thing we need to know is a table 
-> Tables are where our data initially starts 
c.2) When it first gets ingested into our log analytics workspace, the data gets put into a table 

-> Eg event table here is where our windows event logs live. 
c.3) After that we add various types of filters 
-> First two filters below are where filters 
-> So we match places only where we find the word error in event level name and where we have securityLeve="Error"  and we have found the log generated in last 24 hours 
c.4) Once this is done, we will then start to do some summarization 
c.5) We look only top 10 offenders 


Event 
| where (EventLevelName)="Error")
| where (TimeGenerated>ago(1days) 
| summarize ErrorCount=count() by Computer 
| top 10 by ErrorCount dec






Windows Event logs --->Event ------> Event 
Syslog --------------->Syslog<------|  | union syslog
                                       | where EventLevelName="Error"
									   | r SecurityLevel="Error" 
									   
									   
Agents--------------->Heartbeat<---Heartbeat 
									|summarise count()
									 By Computer,bin(TimeGenerated,5min) 
									 
									 
Custom logs-------------->Mylog_CL<---------------------|
                                                        |
Alert rules ------------>Other tables --------------------ALERT
														  | join MyLo_CL on Computer 
														  
														  
														  
d) Demonstration 
-> Review built in log queries 
-> Review the KQL language 

d.1) In Azure portal search for "Monitor" -> Logs -> Queries and search for "heartbeat" to find query related to that -> Run | Load to Editor 
d.2) There we can assign and change scope 

e) Recap:
-> Write your first query with kusto query language 
-> Log analytics workspace is the place where we are going to store all logs,metrics and everything we need to know about how our environment is functioning 

https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-30 end 


31) AZ-104 Course Summary (31 of 31)



https://learn.microsoft.com/en-gb/shows/on-demand-instructor-led-training-series/az-104-module-31

a) Manage azure identities and governance
b) Implement and manage storage 
c) Deploy and manage azure compute resources 
d) COnfigure and manage virtual networking 
e) Monitor and backup resources 

Next is exam preparation videos: AZ-104 exam page 
Review exam study guide 
Demo exam experience with exam sandbox 
Take a practice assessment 
